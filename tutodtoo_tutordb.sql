-- phpMyAdmin SQL Dump
-- version 5.2.1
-- https://www.phpmyadmin.net/
--
-- Host: 127.0.0.1
-- Generation Time: Nov 20, 2025 at 04:38 PM
-- Server version: 10.4.32-MariaDB
-- PHP Version: 8.2.12

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Database: `tutodtoo_tutordb`
--

-- --------------------------------------------------------

--
-- Table structure for table `conversations`
--

CREATE TABLE `conversations` (
  `id` int(11) NOT NULL,
  `user_id` int(11) NOT NULL,
  `title` varchar(255) NOT NULL,
  `created_at` timestamp NOT NULL DEFAULT current_timestamp(),
  `updated_at` timestamp NOT NULL DEFAULT current_timestamp() ON UPDATE current_timestamp()
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `conversations`
--

INSERT INTO `conversations` (`id`, `user_id`, `title`, `created_at`, `updated_at`) VALUES
(5, 1, 'What is Model Context Protocol?', '2025-10-28 02:01:45', '2025-10-28 02:02:32'),
(6, 1, 'Help me debug this Python...', '2025-10-28 02:32:29', '2025-10-28 02:32:36'),
(7, 1, 'Summarize the main causes of...', '2025-10-28 03:06:23', '2025-10-28 03:06:37'),
(8, 1, 'Explain the concept of photosynthesis...', '2025-10-28 03:30:36', '2025-10-28 03:30:44'),
(9, 2, 'New Chat on 2025-10-28', '2025-10-28 07:43:48', '2025-10-28 07:43:48'),
(10, 1, 'What is quantum mechanics?', '2025-10-28 10:45:02', '2025-10-28 10:45:17'),
(11, 1, 'Walk me through the slides', '2025-10-28 11:27:35', '2025-10-28 11:27:56'),
(18, 1, 'New Chat on 2025-10-28', '2025-10-28 21:05:59', '2025-10-28 21:05:59'),
(20, 1, 'Teach me about proofs like...', '2025-10-28 22:46:54', '2025-10-28 22:47:04'),
(21, 1, 'What is the conflict theory?', '2025-10-29 14:33:01', '2025-10-29 14:33:16'),
(22, 3, 'hi', '2025-10-30 12:16:56', '2025-10-30 12:17:01'),
(23, 1, 'Talk about formulas used in...', '2025-10-30 12:17:30', '2025-10-30 12:17:54'),
(24, 1, 'hello chat, i am in...', '2025-11-03 21:17:53', '2025-11-03 21:17:58'),
(25, 1, 'What is RAG in AI?', '2025-11-03 21:38:37', '2025-11-03 21:38:50'),
(26, 4, 'Anscombes quarter', '2025-11-03 22:08:43', '2025-11-03 22:08:53'),
(27, 4, 'New Chat on 2025-11-03', '2025-11-03 22:17:39', '2025-11-03 22:17:39'),
(28, 4, 'What is anscombes quartet and...', '2025-11-03 22:18:30', '2025-11-03 22:18:44'),
(29, 1, 'Explain Anscombe’s quartet', '2025-11-03 22:23:30', '2025-11-03 22:23:40'),
(30, 5, 'What is chemical Pathology', '2025-11-10 07:34:37', '2025-11-10 07:34:45'),
(31, 1, 'Explain the concept of conflict...', '2025-11-13 20:06:39', '2025-11-13 20:06:55'),
(32, 1, 'New Chat on 2025-11-13', '2025-11-13 20:12:22', '2025-11-13 20:12:22'),
(33, 1, 'explain the slides', '2025-11-13 20:16:46', '2025-11-13 20:16:59'),
(37, 1, 'explain chain rule', '2025-11-13 22:12:12', '2025-11-13 22:12:22'),
(38, 1, 'Solve 2x+3=7 step by step', '2025-11-13 22:17:39', '2025-11-13 22:17:50'),
(39, 1, 'Solve 2x+3=7 step by step', '2025-11-13 22:26:44', '2025-11-13 22:26:56'),
(40, 1, 'Solve 2x+3=7 step by step', '2025-11-14 00:20:40', '2025-11-14 00:20:48'),
(41, 1, 'take me through pythagoras theorem', '2025-11-14 00:26:04', '2025-11-14 00:26:10'),
(44, 1, 'explain angular accelaration', '2025-11-14 14:04:56', '2025-11-14 14:05:04'),
(45, 1, 'Explain Anscombe’s quartet', '2025-11-16 00:06:44', '2025-11-16 00:06:55'),
(46, 1, 'Explain the concept of circle...', '2025-11-16 12:04:59', '2025-11-16 12:05:07'),
(48, 6, 'As a university student, teach...', '2025-11-19 01:53:05', '2025-11-19 01:53:14'),
(49, 6, 'what is this about?', '2025-11-19 23:24:10', '2025-11-19 23:24:16'),
(52, 6, 'what is this/', '2025-11-19 23:45:21', '2025-11-19 23:45:29');

-- --------------------------------------------------------

--
-- Table structure for table `messages`
--

CREATE TABLE `messages` (
  `id` int(11) NOT NULL,
  `conversation_id` int(11) NOT NULL,
  `role` enum('user','model') NOT NULL,
  `content` mediumtext NOT NULL,
  `created_at` timestamp NOT NULL DEFAULT current_timestamp()
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `messages`
--

INSERT INTO `messages` (`id`, `conversation_id`, `role`, `content`, `created_at`) VALUES
(9, 5, 'user', '[{\"text\":\"What is Model Context Protocol?\"}]', '2025-10-28 02:01:45'),
(10, 5, 'model', '[{\"text\":\"That\'s a great question, and it points to a fundamental aspect of how large language models (LLMs) like me work! Your goal is to **Understand**, so let\'s break it down clearly.\\n\\nA **Model Context Protocol** refers to the set of rules, strategies, and techniques used to manage and process the `context` that an AI model (especially a large language model) considers when generating a response.\\n\\nThink of it like this:\\n\\nImagine you\'re trying to have a coherent conversation with someone, but you have a very limited short-term memory. You can only remember the last few sentences perfectly. If the conversation goes on too long, or someone brings up a topic from much earlier, you might forget the details that are crucial for a good answer.\\n\\nFor an AI model:\\n\\n1.  **The \\\"Context Window\\\"**: LLMs have a specific limit to how much information they can \\\"pay attention\\\" to at any given time. This is called the `context window`. It\'s measured in \\\"tokens\\\" (which can be words, parts of words, or punctuation). This limit can range from a few thousand tokens to hundreds of thousands.\\n2.  **The Challenge**: If your conversation with the model, or the document you\'ve asked it to analyze, is longer than its context window, the model literally cannot \\\"see\\\" all of the information simultaneously. The older or less relevant parts might get \\\"forgotten\\\" as new information comes in.\\n\\n**This is where the \\\"Model Context Protocol\\\" comes in.** It\'s the strategy for dealing with this context window limitation and making sure the most relevant information is always available to the model.\\n\\nHere are some common aspects of a Model Context Protocol:\\n\\n*   **Truncation**: Simply cutting off parts of the input that exceed the context window. This is the simplest but can lead to loss of important information.\\n*   **Summarization**: Before feeding long text into the model, a system might first summarize that text to condense its key points, ensuring the most vital information fits within the context window.\\n*   **Retrieval Augmented Generation (RAG)**: This is a more advanced technique. Instead of putting *all* potentially relevant information into the context window, the system first retrieves highly specific, relevant pieces of information from a knowledge base (like a database or a set of documents) based on your query. Only these retrieved pieces, along with your query, are then fed to the LLM. This ensures the model has the most precise and up-to-date facts without overflowing its context.\\n*   **Windowing\\/Sliding Window**: For very long documents, the model might process the text in overlapping segments (windows), and then use the output from previous segments to inform the processing of the next.\\n\\n**Why is it important?**\\n\\nA good context protocol helps the AI model to:\\n1.  **Stay Relevant**: Focus on the most important parts of the conversation or document.\\n2.  **Maintain Coherence**: Remember previous turns in a conversation or key themes in a text.\\n3.  **Reduce Hallucinations**: By providing specific, grounded information (especially with RAG), it\'s less likely to \\\"make things up.\\\"\\n4.  **Process Longer Inputs**: Overcome its inherent context window limitations to handle more complex tasks.\\n\\nIn essence, a Model Context Protocol is how we smartly manage the information pipeline to and from an AI, ensuring it\'s always working with the most useful data to give you the best possible response.\\n\\nDoes this explanation help you understand what a Model Context Protocol is and why it\'s so important for AI systems?\"}]', '2025-10-28 02:01:56'),
(11, 6, 'user', '[{\"text\":\"Help me debug this Python code that\'s supposed to sort a list.\"}]', '2025-10-28 02:32:29'),
(12, 6, 'model', '[{\"text\":\"Debugging is a skill every programmer develops, and it can definitely be tricky sometimes! I\'d be happy to help you work through this and understand what\'s happening.\\n\\nTo get started, please share the Python code you\'re trying to debug.\\n\\nOnce I see it, it would be really helpful if you could also tell me:\\n\\n1.  **What is the code *supposed* to do?** (e.g., sort numbers in ascending order, sort strings alphabetically, etc.)\\n2.  **What is it *actually* doing?** Are you getting an error message, or is it producing an incorrect output? If it\'s an incorrect output, what does it look like?\\n3.  **Have you tried any debugging steps yourself already?** What did you try, and what did you observe?\\n\\nKnowing this will help me guide you to understand what\'s going wrong and how to fix it!\"}]', '2025-10-28 02:32:35'),
(13, 7, 'user', '[{\"text\":\"Summarize the main causes of World War II\"}]', '2025-10-28 03:06:23'),
(14, 7, 'model', '[{\"text\":\"That\'s an excellent question to start with! Understanding the main causes of World War II is crucial for grasping one of the most significant events in modern history. It wasn\'t just one single thing, but a complex web of interconnected factors that built up over time.\\n\\nHere are the main causes of World War II, often categorized to help make them clearer:\\n\\n1.  **The Treaty of Versailles (1919):** This peace treaty, which ended World War I, imposed very harsh terms on Germany. It included territorial losses, massive reparations payments, and a \\\"war guilt clause\\\" that forced Germany to accept sole responsibility for the war. This created deep resentment, economic hardship, and a desire for revenge among many Germans, which Hitler later exploited.\\n\\n2.  **The Rise of Totalitarian Regimes:**\\n    *   **Nazism in Germany:** Adolf Hitler and the Nazi Party rose to power with an aggressive, expansionist ideology based on racial superiority and the pursuit of \\\"Lebensraum\\\" (living space) for the German people.\\n    *   **Fascism in Italy:** Benito Mussolini\'s fascist government glorified military strength and sought to restore Italy\'s imperial glory.\\n    *   **Militarism in Japan:** A militaristic government in Japan pursued aggressive expansion in Asia, seeking raw materials and dominance in the region.\\n\\n3.  **Appeasement:** This was a foreign policy adopted primarily by Britain and France in the 1930s. To avoid another devastating war, they repeatedly gave in to the demands of aggressive dictators, particularly Hitler. Examples include allowing Germany to re-militarize the Rhineland, annex Austria (the \\\"Anschluss\\\"), and take over the Sudetenland region of Czechoslovakia. This policy, instead of satisfying Hitler, only emboldened him and convinced him that democratic nations were weak and unwilling to fight.\\n\\n4.  **Failure of the League of Nations:** Created after World War I to promote international cooperation and prevent future wars, the League of Nations proved ineffective. It lacked its own military force, key powers like the United States never joined, and it failed to take decisive action against acts of aggression (such as Japan\'s invasion of Manchuria, Italy\'s invasion of Ethiopia, or Germany\'s rearmament). This demonstrated that there was no strong international body capable of maintaining peace.\\n\\n5.  **Expansionism and Aggression:** The aggressive foreign policies of Germany, Italy, and Japan directly led to conflict. Germany invaded Poland in September 1939, triggering declarations of war from Britain and France and officially starting World War II in Europe. Japan\'s continued aggression in China and Southeast Asia eventually led to conflict with the United States.\\n\\nIn essence, a punitive peace treaty, the rise of aggressive dictatorships, a failure of international diplomacy, and the policy of trying to avoid war at all costs created a climate where conflict became almost inevitable.\\n\\nDoes this summary help you understand the major contributing factors? Is there any specific cause you\'d like to explore in more detail, or perhaps a concept like \\\"appeasement\\\" or \\\"totalitarianism\\\" that you\'d like me to explain further?\"}]', '2025-10-28 03:06:37'),
(15, 8, 'user', '[{\"text\":\"Explain the concept of photosynthesis in simple terms.\"}]', '2025-10-28 03:30:36'),
(16, 8, 'model', '[{\"text\":\"That\'s a fantastic question! Photosynthesis is one of the most important processes on Earth, and it\'s how plants (and some other organisms) make their own food.\\n\\nLet\'s break it down into simple terms, like a plant\'s tiny kitchen:\\n\\nImagine a plant as a chef, and its leaves are its kitchen. This chef needs three main \\\"ingredients\\\" to cook up some food:\\n\\n1.  **Sunlight:** This is the energy source, like the oven that powers the cooking. Plants capture this light using a special green pigment called **chlorophyll**, which is why most plants are green!\\n2.  **Water (H\\u2082O):** The plant sips this up from the soil through its roots.\\n3.  **Carbon Dioxide (CO\\u2082):** The plant breathes this in from the air through tiny pores in its leaves. This is the same gas we breathe out!\\n\\nNow, what does the plant \\\"cook\\\"?\\n\\nUsing the energy from sunlight, the plant takes the water and carbon dioxide and transforms them. The \\\"food\\\" it makes is a type of **sugar (glucose)**, which gives the plant energy to grow, flower, and produce fruit.\\n\\nAs a bonus \\\"side dish\\\" or byproduct of this cooking process, the plant releases **oxygen (O\\u2082) into the air**. This is incredibly important for us and most other living things, as we need oxygen to breathe!\\n\\n**In short:**\\n\\nPlants use sunlight, water, and carbon dioxide to create their own food (sugar) for energy, and they release oxygen as a byproduct.\\n\\nDoes that explanation of a plant\'s \\\"kitchen\\\" help clarify what photosynthesis is all about?\"}]', '2025-10-28 03:30:43'),
(17, 10, 'user', '[{\"text\":\"What is quantum mechanics?\"}]', '2025-10-28 10:45:02'),
(18, 10, 'model', '[{\"text\":\"That\'s a fantastic question to dive into! Quantum mechanics is one of the most fundamental and fascinating theories in physics.\\n\\nThink of it this way: **Classical mechanics** (like Newton\'s laws) does a great job explaining how large objects move \\u2013 how a car drives, how a baseball flies, or how planets orbit the sun. But when we zoom in to the incredibly tiny world of atoms and subatomic particles (like electrons and photons), classical mechanics starts to break down and doesn\'t accurately describe what\'s happening.\\n\\n**Quantum mechanics** is the branch of physics that was developed to explain the behavior of matter and energy at these extremely small scales. It gives us a completely new, and often counter-intuitive, way to understand the universe.\\n\\nHere are a few core ideas that make quantum mechanics unique:\\n\\n1.  **Quantization**: Imagine a light switch that\'s either on or off, with no in-between states. In the quantum world, many physical properties like energy, momentum, or spin can only exist in discrete, specific \\\"packets\\\" or \\\"quanta,\\\" rather than being able to take on any continuous value. It\'s like a staircase where you can only stand on steps, not in between them.\\n2.  **Wave-Particle Duality**: This is a mind-bender! Quantum particles can behave like both particles (tiny bits of matter with a definite position) AND waves (spread out, oscillating disturbances) at the same time. For example, light, which we usually think of as a wave, also comes in discrete particle-like packets called photons. And electrons, which we usually think of as particles, can also show wave-like behavior.\\n3.  **Probability and Uncertainty**: Unlike classical physics where we can predict exact outcomes, quantum mechanics often describes the *probability* of an event happening. We can\'t always know all the properties of a quantum particle with perfect certainty simultaneously. For instance, the **Heisenberg Uncertainty Principle** states that you can\'t simultaneously know both the exact position and the exact momentum of a particle. The more precisely you know one, the less precisely you can know the other.\\n\\nIn essence, quantum mechanics is our best description of the microscopic world, revealing a universe that is far stranger and more complex than what we perceive in our everyday macroscopic lives, yet incredibly successful at predicting experimental outcomes.\\n\\nDoes this initial overview help you start to grasp what quantum mechanics is about? What part of it seems most intriguing or confusing to you?\"}]', '2025-10-28 10:45:16'),
(19, 11, 'user', '[{\"text\":\"Context from uploaded file \'lecture 2 slides.pdf\':\\n---\\n2\\/20\\/2024\\n1\\nLED 130: Issues in \\nEnvironmental science\\nlecture 2\\nBy Dr. Elizabeth D. Agyei\\n1\\n2\\n\\n2\\/20\\/2024\\n2\\n3\\n4\\n\\n2\\/20\\/2024\\n3\\nOnly less than 1% is fresh water  and available for human exploitations\\n5\\n6\\n\\n2\\/20\\/2024\\n4\\n7\\n8\\n\\n2\\/20\\/2024\\n5\\nSoil\\nGold\\nminerals\\n9\\n10\\n\\n2\\/20\\/2024\\n6\\n11\\n12\\n\\n2\\/20\\/2024\\n7\\n13\\n14\\n\\n2\\/20\\/2024\\n8\\n15\\n16\\n\\n2\\/20\\/2024\\n9\\n17\\n18\\n\\n2\\/20\\/2024\\n10\\n19\\n20\\n\\n2\\/20\\/2024\\n11\\nReading Assignment : Creation and \\nStewardship of the Environment\\nTask: \\n \\nDiscuss the concept  of environment from the \\nperspective of :\\ni.Christian Religion\\nii.Islam religion and \\niii.African Traditional religion\\nCheck the course platform on the UCC lms for reading \\nmaterials pertaining to this assignment and \\nsubmission details\\u2026.\\n21\\n22\\n---\\n\\nUser\'s question: Walk me through the slides\"}]', '2025-10-28 11:27:35'),
(20, 11, 'model', '[{\"text\":\"Certainly! I can walk you through the key points of this lecture, based on the provided slides. It covers some foundational concepts in environmental science and outlines an important assignment.\\n\\nLet\'s break down the content by the topics presented:\\n\\n1.  **Slides 1 & 2: Introduction to the Course and Lecture**\\n    *   These slides simply set the stage. They introduce the course: `LED 130: Issues in Environmental Science`, identify it as `lecture 2`, and name the presenter: `Dr. Elizabeth D. Agyei`. This is just orienting information.\\n\\n2.  **Slides 3-6: Global Water Distribution and Scarcity**\\n    *   Slides 3 and 4 likely contained a visual representation (like a pie chart or diagram) of how water is distributed across the Earth.\\n    *   The crucial point comes from slides 5 and 6, which explicitly state: \\\"Only less than 1% is fresh water and available for human exploitations\\\".\\n    *   **Key Concept**: This highlights a major issue in environmental science \\u2013 the immense scarcity of readily available freshwater. Even though Earth is called the \\\"blue planet,\\\" most of that water is saltwater in oceans, or locked up in glaciers and ice caps. The tiny fraction that\'s easily usable by humans is a vital, limited resource.\\n\\n3.  **Slides 7 & 8 and 11-20: Gaps in Content**\\n    *   Based on the provided text, slides 7, 8, and then slides 11 through 20 do not contain any transcribed content. It\'s possible these slides held images, diagrams, or were meant for discussion points during the live lecture that aren\'t captured in the text.\\n\\n4.  **Slides 9 & 10: Examples of Natural Resources**\\n    *   These slides list three specific examples of natural resources: `Soil`, `Gold`, and `minerals`.\\n    *   **Key Concept**: Natural resources are materials or substances occurring in nature which can be exploited for economic gain. Understanding their availability, extraction, and sustainable use is central to environmental science.\\n\\n5.  **Slides 21 & 22: Reading Assignment**\\n    *   This section details an important assignment titled: \\\"Creation and Stewardship of the Environment\\\".\\n    *   **Your Task**: You need to discuss the concept of the environment from the perspective of three different religious traditions:\\n        *   i. Christian Religion\\n        *   ii. Islam religion\\n        *   iii. African Traditional religion\\n    *   The slides also direct you to \\\"Check the course platform on the UCC lms for reading materials pertaining to this assignment and submission details.\\\"\\n\\n---\\n\\n**In summary**, this lecture introduces the course, immediately brings attention to the critical environmental issue of freshwater scarcity, gives examples of natural resources, and concludes by assigning a task to explore the concept of environmental stewardship through religious lenses.\\n\\nDid this walk-through help you understand the overall flow and main points of the slides, especially the idea of water scarcity? Do you have any questions about the assignment, or perhaps why religious perspectives might be important in environmental science?\"}]', '2025-10-28 11:27:55'),
(29, 18, 'user', '[{\"text\":\"Walk me through the Egyptian history\"}]', '2025-10-28 21:05:59'),
(30, 18, 'model', '[{\"text\":\"That\'s a fantastic topic! Ancient Egyptian history spans thousands of years and is incredibly rich and fascinating. To help you remember the key phases, let\'s break it down into major periods, like chapters in a very long book.\\n\\nThink of it as starting with small villages along the Nile, growing into a unified kingdom, reaching incredible heights of power and culture, facing challenges, and eventually being absorbed by larger empires.\\n\\nHere\'s a general overview of the main periods:\\n\\n1.  **Predynastic Period (c. 6000 \\u2013 3100 BCE):**\\n    *   Before the pharaohs! This was when early agricultural communities settled along the Nile.\\n    *   They developed distinct cultures, some of which eventually merged.\\n    *   Towards the end, two main kingdoms emerged: Upper Egypt (south) and Lower Egypt (north).\\n\\n2.  **Early Dynastic Period (c. 3100 \\u2013 2686 BCE):**\\n    *   This is when Egypt was **unified** under one ruler!\\n    *   **King Narmer** (or Menes, depending on the source) is often credited with uniting Upper and Lower Egypt, establishing the first dynasty.\\n    *   The capital was Memphis, near modern-day Cairo.\\n\\n3.  **Old Kingdom (c. 2686 \\u2013 2181 BCE):**\\n    *   Often called the \\\"Age of the Pyramids.\\\"\\n    *   Pharaohs were seen as living gods. This period saw the construction of the Great Pyramids of Giza for pharaohs like **Khufu**, Khafre, and Menkaure, and the Step Pyramid of Djoser.\\n    *   Centralized government was very strong.\\n\\n4.  **First Intermediate Period (c. 2181 \\u2013 2055 BCE):**\\n    *   A time of political fragmentation and decentralization.\\n    *   The central government weakened, and regional governors (nomarchs) gained more power, leading to civil strife.\\n\\n5.  **Middle Kingdom (c. 2055 \\u2013 1650 BCE):**\\n    *   Egypt was reunited under a new line of pharaohs.\\n    *   Known for its literary achievements, more focus on the well-being of the common people, and significant expansion of irrigation projects.\\n    *   Pharaohs like **Senusret III** expanded Egypt\'s borders.\\n\\n6.  **Second Intermediate Period (c. 1650 \\u2013 1550 BCE):**\\n    *   Another period of instability.\\n    *   The **Hyksos**, foreign invaders from the Near East, conquered and ruled Lower Egypt for a time, introducing new technologies like the horse and chariot.\\n\\n7.  **New Kingdom (c. 1550 \\u2013 1070 BCE):**\\n    *   This is often considered the most powerful and prosperous era of ancient Egypt, an \\\"Empire Age.\\\"\\n    *   Pharaohs like **Hatshepsut** (a powerful female pharaoh), **Thutmose III** (a great military conqueror), **Akhenaten** (who tried to introduce monotheism), **Tutankhamun** (famous for his intact tomb), and **Ramesses II** (the Great, who built many temples and fought the Battle of Kadesh) ruled during this time.\\n    *   Egypt expanded its empire far into the Near East and Nubia.\\n\\n8.  **Late Period & Foreign Domination (c. 1070 BCE \\u2013 30 BCE):**\\n    *   After the New Kingdom, Egypt gradually declined in power.\\n    *   It was often ruled by foreign powers:\\n        *   Various native Egyptian dynasties tried to reassert control.\\n        *   **Persians** conquered Egypt multiple times.\\n        *   **Alexander the Great** conquered Egypt in 332 BCE, leading to the **Ptolemaic Dynasty**.\\n        *   The **Ptolemaic Dynasty** was founded by Ptolemy I Soter (one of Alexander\'s generals) and ruled for nearly 300 years, with **Cleopatra VII** being its last pharaoh.\\n        *   Finally, Egypt became a province of the **Roman Empire** after Cleopatra\'s defeat in 30 BCE.\\n\\nThis journey covers roughly 3,000 years!\\n\\nTo help you get started remembering this vast history, what part of this timeline sounds most interesting to you? Or, which period do you want to dive into first?\"}]', '2025-10-28 21:06:17'),
(33, 20, 'user', '[{\"text\":\"Teach me about proofs like you\'re teaching a 5 year old\"}]', '2025-10-28 22:46:54'),
(34, 20, 'model', '[{\"text\":\"Oh, teaching proofs to a 5-year-old? That sounds like a super fun game! Let\'s pretend we\'re super-duper detectives.\\n\\nImagine you have a really yummy cookie. And then... *poof*... the cookie is gone! Someone might just say, \\\"The cookie is gone!\\\" But how do we *know* it\'s really, really gone?\\n\\nA **proof** is like being that super detective who finds **all the clues** and shows them to everyone, so that everyone agrees, \\\"Yes! That cookie is definitely, absolutely gone!\\\" It\'s like finding a big, shiny, undeniable \\\"YES!\\\" button for what you\'re trying to show.\\n\\nSo, for our cookie mystery, what clues would you look for to **prove** it\'s gone?\\n*   You might see an empty plate! (Clue 1)\\n*   You might see tiny crumbs on the table! (Clue 2)\\n*   And maybe, just maybe, you see a little chocolate smudge on *my* face! (Uh oh, Clue 3!)\\n\\nWhen you put all those clues together \\u2013 the empty plate, the crumbs, the chocolate smudge \\u2013 you\'ve made a **proof**! You\'ve shown everyone, with clear reasons, that the cookie is definitely, absolutely gone. No one can say, \\\"No, the cookie is still there!\\\" because you have all the reasons why it\'s true.\\n\\nSo, a proof is just collecting all the best reasons and showing them off, so everyone knows something is 100% true!\\n\\nDoes that make sense? Can you think of something else you might want to prove to your grown-up, using clues?\"}]', '2025-10-28 22:47:04'),
(35, 21, 'user', '[{\"text\":\"What is the conflict theory?\"}]', '2025-10-29 14:33:01'),
(36, 21, 'model', '[{\"text\":\"That\'s a great question! Conflict theory is a fundamental perspective in sociology and other social sciences, offering a powerful way to understand how societies function \\u2013 or sometimes, *malfunction*.\\n\\nAt its core, **Conflict Theory** suggests that society is in a perpetual state of conflict due to competition for limited resources. It posits that social order is maintained by domination and power, rather than consensus and conformity.\\n\\nHere are some key ideas to help you understand it better:\\n\\n*   **Competition and Inequality**: Conflict theory assumes that there are always conflicts of interest between different groups in society (e.g., the wealthy vs. the poor, men vs. women, dominant ethnic groups vs. minority groups). These groups are competing for resources like wealth, power, prestige, and even ideas.\\n*   **Power Dynamics**: Those with more power and resources tend to create and maintain social structures (laws, institutions, norms) that benefit themselves, often at the expense of less powerful groups. This perpetuates inequality.\\n*   **Change as a Result of Conflict**: From this perspective, social change doesn\'t happen gradually through smooth evolution but rather through revolutionary or significant shifts brought about by the struggle between these competing groups. When suppressed groups challenge the status quo, society changes.\\n\\nThe roots of modern conflict theory are most strongly associated with **Karl Marx**, who focused on the economic struggle between the bourgeoisie (owners of capital and means of production) and the proletariat (workers). However, the theory has since been expanded to analyze other forms of conflict and inequality, such as those based on:\\n*   **Gender**: Feminist theory, for example, uses conflict theory to analyze power imbalances and systemic oppression faced by women.\\n*   **Race\\/Ethnicity**: Critical race theory draws on conflict theory to examine how racial and ethnic minorities experience systemic oppression and inequality.\\n*   **Age, Religion, Sexual Orientation, and other social categories.**\\n\\nIn essence, while other sociological theories might see society as a largely cooperative system where everyone has a role (like a body with different organs), conflict theory highlights the inherent tensions, power imbalances, and struggles that shape social life.\\n\\nDoes this initial explanation make sense? What part of it stood out to you, or what further questions do you have about it?\"}]', '2025-10-29 14:33:16'),
(37, 22, 'user', '[{\"text\":\"hi\"}]', '2025-10-30 12:16:56'),
(38, 22, 'model', '[{\"text\":\"Hello there! I\'m ready to help you learn something new today.\\n\\nWhat subject are you interested in, or what specific concept are you hoping to **understand** better? Just let me know what\'s on your mind!\"}]', '2025-10-30 12:17:01'),
(39, 22, 'user', '[{\"text\":\"2\"}]', '2025-10-30 12:17:10'),
(40, 22, 'model', '[{\"text\":\"Hmm, \\\"2.\\\" That\'s an interesting number!\\n\\nCould you tell me a bit more about what \\\"2\\\" refers to? Are you thinking about:\\n\\n*   A specific question number?\\n*   A quantity?\\n*   Perhaps a concept related to the number two?\\n\\nJust let me know what you\'d like to explore or **understand**! \\ud83d\\ude0a\"}]', '2025-10-30 12:17:14'),
(41, 23, 'user', '[{\"text\":\"Talk about formulas used in machine learning\"}]', '2025-10-30 12:17:30'),
(42, 22, 'user', '[{\"text\":\"2-2x4+7x5\"}]', '2025-10-30 12:17:30'),
(43, 22, 'model', '[{\"text\":\"That\'s a good mathematical expression to work through! It involves a few different operations: subtraction (`-`) and multiplication (`x`).\\n\\nThe key to **understanding** how to solve expressions like `\\\\(2 - 2 \\\\times 4 + 7 \\\\times 5\\\\)` correctly is knowing the **order of operations**.\\n\\nDo you remember any rules or a mnemonic (like PEMDAS or BODMAS) that helps us decide which operations to perform first? Or, what\'s your initial thought on which part of the expression we should tackle first?\\n\\nNo worries if you\'re unsure, we can explore it step-by-step!\"}]', '2025-10-30 12:17:39'),
(44, 23, 'model', '[{\"text\":\"That\'s a fantastic question to dive into! Machine learning is powered by mathematics, and formulas are at the heart of how these algorithms learn and make predictions.\\n\\nThe user\'s goal is to **Understand**. So, instead of just listing formulas, I\'ll explain the purpose behind some key ones, what their components mean, and why they\'re important. We\'ll start with some fundamental concepts to build a solid foundation.\\n\\nLet\'s explore some core formulas used in machine learning, focusing on what they help us achieve:\\n\\n### 1. The Prediction Formula (e.g., Linear Regression)\\n\\nMany machine learning tasks involve predicting a value or classifying something. One of the simplest yet most foundational is **Linear Regression**, where we try to find a linear relationship between input features and an output.\\n\\n**Purpose**: To model the relationship between input features ($x$) and a continuous output ($y$) by finding the best-fit line (or hyperplane).\\n\\n**Formula (Simple Linear Regression)**:\\n$$ h_\\\\theta(x) = \\\\theta_0 + \\\\theta_1 x $$\\n\\n**Let\'s break it down:**\\n*   $h_\\\\theta(x)$: This is our **prediction** (also called the \\\"hypothesis\\\"). It\'s what the model thinks the output should be for a given input $x$.\\n*   $x$: This is the **input feature** (e.g., the size of a house).\\n*   $\\\\theta_0$: This is the **y-intercept** (also called the bias term). It\'s the predicted value of $y$ when $x$ is 0.\\n*   $\\\\theta_1$: This is the **slope** (also called the weight or coefficient for $x$). It tells us how much $y$ is expected to change for every one-unit increase in $x$.\\n\\n**Analogy**: Imagine you\'re trying to predict house prices based on their size. $x$ would be the size, $y$ would be the price. $\\\\theta_1$ tells you how much the price generally goes up for each extra square foot, and $\\\\theta_0$ might represent a base price for even tiny houses or the value of the land.\\n\\nThis formula can be extended for multiple input features (multivariate linear regression):\\n$$ h_\\\\theta(x) = \\\\theta_0 + \\\\theta_1 x_1 + \\\\theta_2 x_2 + \\\\dots + \\\\theta_n x_n $$\\nOr, more compactly using vector notation:\\n$$ h_\\\\theta(x) = \\\\theta^T x $$\\nwhere $\\\\theta$ and $x$ are vectors.\\n\\n### 2. The Cost Function (e.g., Mean Squared Error - MSE)\\n\\nOur prediction formula above needs to be \\\"tuned\\\" so that its predictions ($h_\\\\theta(x)$) are as close as possible to the actual observed values ($y$). A **Cost Function** (or Loss Function) is what we use to measure how \\\"wrong\\\" our model\'s predictions are. The goal of training a machine learning model is usually to *minimize* this cost function.\\n\\n**Purpose**: To quantify the error between the model\'s predictions and the actual target values. A lower cost means a better-fitting model.\\n\\n**Formula (Mean Squared Error)**:\\n$$ J(\\\\theta) = \\\\frac{1}{2m} \\\\sum_{i=1}^{m} (h_\\\\theta(x^{(i)}) - y^{(i)})^2 $$\\n\\n**Let\'s break it down:**\\n*   $J(\\\\theta)$: This is the **cost function**, and we want to find the values of $\\\\theta$ (our $\\\\theta_0, \\\\theta_1, \\\\dots$) that make this value as small as possible.\\n*   $m$: The total number of **training examples** (data points) we have.\\n*   $i$: An index to refer to a specific training example. $(x^{(i)}, y^{(i)})$ represents the $i$-th example.\\n*   $h_\\\\theta(x^{(i)})$: Our model\'s **prediction** for the $i$-th example.\\n*   $y^{(i)}$: The **actual, true value** for the $i$-th example.\\n*   $(h_\\\\theta(x^{(i)}) - y^{(i)})$: This is the **error** (or residual) for a single example \\u2013 how far off our prediction is from the truth.\\n*   $(h_\\\\theta(x^{(i)}) - y^{(i)})^2$: We **square the error** to make sure positive and negative errors don\'t cancel out, and to penalize larger errors more heavily.\\n*   $\\\\sum_{i=1}^{m} (...)$: We **sum up** the squared errors for *all* our training examples.\\n*   $\\\\frac{1}{2m}$: We **average** the squared errors over all examples (the $\\\\frac{1}{2}$ is often included for mathematical convenience when calculating derivatives later, but the essence is averaging).\\n\\n**Analogy**: If you\'re playing darts, the cost function measures how far your darts land from the bullseye, on average. You want to adjust your throw (your $\\\\theta$ values) until this average distance (your cost) is minimized.\\n\\n### 3. The Activation Function (e.g., Sigmoid)\\n\\nWhile linear regression is great for continuous output values, what if we want to classify something (e.g., \\\"is this email spam or not?\\\" or \\\"will this customer buy or not?\\\")? This is where **activation functions** come in, particularly in algorithms like Logistic Regression and Neural Networks. They introduce non-linearity and often map outputs to a specific range (like probabilities between 0 and 1).\\n\\n**Purpose**: To transform the raw linear output of a model into a more meaningful format, often a probability or a non-linear activation.\\n\\n**Formula (Sigmoid Function)**:\\n$$ \\\\sigma(z) = \\\\frac{1}{1 + e^{-z}} $$\\n\\n**Let\'s break it down:**\\n*   $\\\\sigma(z)$: This is the **output of the sigmoid function**, which will always be a value between 0 and 1.\\n*   $z$: This is often the **linear combination of inputs and weights** from the previous layer or step (e.g., $z = \\\\theta^T x$ from our prediction formula).\\n*   $e$: Euler\'s number (the base of the natural logarithm), approximately 2.71828. It\'s a fundamental mathematical constant.\\n\\n**How it works**:\\nThe sigmoid function takes any real number ($z$) as input and squashes it into an output between 0 and 1. This makes it very useful for binary classification tasks, where the output can be interpreted as the probability of belonging to a certain class. If $\\\\sigma(z)$ is close to 1, it\'s highly likely to be in class 1; if close to 0, it\'s highly likely to be in class 0.\\n\\n**Analogy**: Imagine a switch that turns on gradually. The input $z$ is like how much you push the switch. A small push might give a low output (close to 0), a big push gives a high output (close to 1), and there\'s a smooth transition in between. It helps convert a \\\"strength of evidence\\\" (your $z$) into a \\\"probability.\\\"\\n\\n---\\n\\nThese three types of formulas\\u2014a **prediction formula**, a **cost function**, and an **activation function**\\u2014are fundamental building blocks in many machine learning algorithms.\\n\\nDoes explaining them in this way help you understand their roles better? Would you like to delve deeper into any of these, or perhaps explore other types of formulas, like those related to optimization or specific algorithms?\"}]', '2025-10-30 12:17:52'),
(45, 22, 'user', '[{\"text\":\"record 2x5\"}]', '2025-10-30 12:21:34'),
(46, 22, 'model', '[{\"text\":\"That\'s an excellent start! You\'re absolutely right that `\\\\(2 \\\\times 5\\\\)` is one of the multiplication operations we need to address first, according to the order of operations.\\n\\nWhat is the result of `\\\\(2 \\\\times 5\\\\)`?\\n\\nAnd looking back at the original expression: `\\\\(2 - 2 \\\\times 4 + 7 \\\\times 5\\\\)`\\n\\nBesides `\\\\(2 \\\\times 5\\\\)`, are there any other multiplication operations in that expression that we should calculate before moving on to addition or subtraction?\"}]', '2025-10-30 12:21:40'),
(47, 22, 'user', '[{\"text\":\"can you intercat\"}]', '2025-10-30 12:21:50'),
(48, 22, 'model', '[{\"text\":\"Ah, you mean \\\"interact\\\"! Yes, absolutely! That\'s exactly what I\'m here for. \\ud83d\\ude0a\\n\\nMy goal is to have a dynamic conversation with you, guide you through concepts, and help you discover understanding step-by-step. So please, feel free to ask questions, tell me your thoughts, or ask me to explain things differently at any point.\\n\\nI\'m ready to interact however is most helpful for your learning!\\n\\nSo, coming back to our math problem `\\\\(2 - 2 \\\\times 4 + 7 \\\\times 5\\\\)`:\\n\\nYou correctly pointed out `\\\\(2 \\\\times 5\\\\)` as one of the multiplications to do. What other multiplication operation did you notice in the expression that we should calculate?\"}]', '2025-10-30 12:21:56'),
(49, 24, 'user', '[{\"text\":\"hello chat, i am in a dull mood today\"}]', '2025-11-03 21:17:53'),
(50, 24, 'model', '[{\"text\":\"I\'m sorry to hear you\'re in a dull mood today. It happens to us all! Sometimes a little mental challenge or exploring a new topic can be a great way to spark some curiosity and lift your spirits.\\n\\nAs your AI tutor, I\'m here to make learning engaging and help you understand things better, whatever the subject.\\n\\nIs there anything at all that you\'ve been curious about, or something you\'d like to dive into today, even if it\'s just for a little while? We can take it at your own pace.\"}]', '2025-11-03 21:17:58'),
(51, 24, 'user', '[{\"text\":\"i want to make money\"}]', '2025-11-03 21:18:54'),
(52, 24, 'model', '[{\"text\":\"That\'s a very clear and practical goal! Many people share that desire, and there are countless paths to making money, each requiring different skills, efforts, and strategies.\\n\\nTo help you figure out the best path for you, we can explore different ways people make money and what might be involved. My goal here is to help you **understand** the various avenues and then perhaps **apply** that understanding to your own situation.\\n\\nTo get started, could you tell me a little more about what \\\"making money\\\" means to you right now? For example:\\n\\n1.  **What kind of money are you thinking about?** (e.g., a little extra income on the side, enough to cover a specific bill, a full-time income, or building long-term wealth?)\\n2.  **How much time are you willing or able to dedicate to this?** (e.g., a few hours a week, full-time, weekends only?)\\n3.  **Are there any existing skills, hobbies, or interests you have that you enjoy?** (e.g., writing, designing, solving problems, talking to people, working with your hands, technology, art, cooking?)\\n4.  **Are you looking for something short-term and immediate, or something that could grow into a bigger opportunity over time?**\\n\\nNo need to have all the answers, just tell me what comes to mind. Your answers will help us narrow down the vast possibilities and find some learning paths that might be exciting for you!\"}]', '2025-11-03 21:19:04'),
(53, 24, 'user', '[{\"text\":\"i am currently a software engineer and i am looking for means to make money in my field of expertise.. any advice for me on how to go about it\"}]', '2025-11-03 21:21:07'),
(54, 24, 'model', '[{\"text\":\"That\'s an excellent clarification! As a software engineer, you\'re in a fantastic position to leverage your skills in numerous ways beyond a traditional full-time role to generate income. Your expertise is in high demand, and the digital nature of your work opens up many flexible and scalable opportunities.\\n\\nMy goal here is to help you **understand** some of the most common and effective avenues for software engineers to make money, and then help you think about which ones might align best with your own interests, time, and specific skills.\\n\\nHere are some popular ways software engineers make money outside of or in addition to their main employment:\\n\\n1.  **Freelancing and Consulting:**\\n    *   **What it is:** Offering your services on a project-by-project basis to various clients. This could involve building websites, mobile apps, custom software, backend APIs, or even providing specialized technical advice.\\n    *   **Pros:** High hourly rates, flexibility, diverse projects, builds a strong portfolio.\\n    *   **Cons:** Inconsistent income, requires active client acquisition, administrative overhead (contracts, invoicing).\\n    *   **Example:** A company needs a specific integration with a third-party service, and they hire you for a 2-month contract to build it.\\n\\n2.  **Building and Selling Your Own Products (SaaS, Apps, Digital Goods):**\\n    *   **What it is:** Creating a software product (Software-as-a-Service, a mobile app, a desktop utility, a plugin, a template, an e-book on a technical topic) and selling it directly to users or businesses. This is often referred to as \\\"bootstrapping a startup\\\" or building a \\\"micro-SaaS.\\\"\\n    *   **Pros:** Highly scalable, potential for passive recurring income, full creative control, can be very rewarding.\\n    *   **Cons:** Requires significant upfront time and effort, involves marketing and sales, no guaranteed success, high risk.\\n    *   **Example:** You notice a common pain point for other developers and build a small tool or service that automates a tedious task, then charge a monthly subscription for it.\\n\\n3.  **Technical Content Creation & Education:**\\n    *   **What it is:** Sharing your knowledge and expertise through various mediums. This could include:\\n        *   **Blogging:** Writing articles about technical topics (monetized through ads, affiliate links, sponsorships, or leading to product sales).\\n        *   **Online Courses:** Creating in-depth video or text-based courses on platforms like Udemy, Coursera, or your own site.\\n        *   **YouTube\\/Twitch:** Creating video tutorials, live coding sessions, or tech reviews.\\n        *   **Technical Books\\/E-books:** Writing and self-publishing guides on specific technologies.\\n        *   **Mentoring\\/Tutoring:** Offering one-on-one or group coaching to aspiring developers.\\n    *   **Pros:** Builds your personal brand, can generate passive income, helps others, deepens your own understanding.\\n    *   **Cons:** Takes time to build an audience, requires good communication skills, initial income can be low.\\n    *   **Example:** You create a comprehensive online course on \\\"Mastering React Hooks\\\" and sell it.\\n\\n4.  **Open Source Contributions & Sponsorships:**\\n    *   **What it is:** Contributing significantly to popular open-source projects, which can sometimes lead to direct financial support through platforms like GitHub Sponsors or Open Collective, or indirectly through increased visibility for consulting gigs.\\n    *   **Pros:** Enhances your reputation, improves your skills, contributes to the community.\\n    *   **Cons:** Income is often supplementary and not guaranteed, requires dedication and visibility within the open-source community.\\n    *   **Example:** You maintain a widely used Python library and receive monthly donations from companies that rely on your work.\\n\\n5.  **Algorithmic Trading \\/ Quantitative Finance (Specialized Niche):**\\n    *   **What it is:** Applying your programming skills to develop automated trading strategies or analysis tools for financial markets. This typically involves complex algorithms, data analysis, and often requires strong mathematical and statistical skills in addition to programming.\\n    *   **Pros:** High potential returns, intellectually stimulating, directly leverages advanced programming.\\n    *   **Cons:** Very high risk (you can lose money), requires deep financial market knowledge, often requires significant capital to start.\\n    *   **Example:** You build a high-frequency trading bot that identifies and executes trades based on specific market conditions.\\n\\n---\\n\\nConsidering these avenues, which one (or combination) sparks your interest the most? Or perhaps, thinking about your current skills and what you enjoy doing as a software engineer, which of these feels like the most natural fit for you to explore further?\"}]', '2025-11-03 21:21:25'),
(55, 25, 'user', '[{\"text\":\"What is RAG in AI?\"}]', '2025-11-03 21:38:37'),
(56, 25, 'model', '[{\"text\":\"That\'s a great question about a very important concept in modern AI! It shows you\'re digging into how these powerful systems actually work.\\n\\nRAG stands for **Retrieval-Augmented Generation**.\\n\\nTo **understand** RAG, let\'s break down what it is and why it\'s so useful, especially with Large Language Models (LLMs) like the one we\'re using now:\\n\\n### What is RAG?\\n\\nImagine an AI system that\'s been trained on a massive amount of text. It has a lot of general knowledge, but there are some common issues:\\n\\n1.  **Outdated Information**: Its knowledge is only as current as its last training data.\\n2.  **Hallucinations**: It might \\\"make up\\\" plausible-sounding but incorrect information.\\n3.  **Lack of Specific Domain Knowledge**: It might not know the intricate details of *your* company\'s internal documents or the very latest scientific research.\\n\\nRAG is a technique designed to address these problems. It gives an LLM the ability to **look up information from external, trusted sources** *before* generating a response.\\n\\nHere\'s how it generally works in three steps:\\n\\n1.  **Retrieval**: When you ask a question, the RAG system first searches a private or external knowledge base (like a database of your company\'s documents, a specific website, or even the latest research papers). It \\\"retrieves\\\" the most relevant pieces of information related to your question.\\n2.  **Augmentation**: These retrieved pieces of information are then added to your original question, creating an \\\"augmented\\\" prompt.\\n3.  **Generation**: This augmented prompt (your question + the retrieved context) is then fed to the LLM. The LLM uses this fresh, relevant, and accurate information to generate its answer, rather than relying solely on its internal, potentially outdated or general knowledge.\\n\\n### Why is RAG useful?\\n\\n*   **Factual Accuracy**: It significantly reduces the likelihood of the LLM \\\"making things up\\\" or providing outdated information.\\n*   **Up-to-Date Information**: LLMs can answer questions about very recent events or specific, frequently changing data without needing to be fully retrained.\\n*   **Domain-Specific Knowledge**: It allows LLMs to interact with and use knowledge that was never part of their initial training, making them useful for specialized tasks (e.g., answering questions about a company\'s internal policies, medical records, or legal documents).\\n*   **Reduced Hallucinations**: By grounding the LLM\'s response in verifiable external data, it\'s less likely to generate incorrect or nonsensical output.\\n*   **Transparency**: Sometimes, RAG systems can even cite their sources, allowing you to verify the information.\\n\\n### Analogy:\\n\\nThink of it like this:\\n\\n*   **Without RAG**: The AI is like a brilliant student taking an exam who can only use what they remember from their classes. They\'re very knowledgeable, but their info might be a bit old, and they might sometimes confidently guess if they don\'t know something exactly.\\n*   **With RAG**: That same brilliant student is now allowed to consult a *specific, up-to-date section of the library* or a *trusted expert\'s notes* for each question *before* they write their answer. They can still use their brilliance to synthesize, but their answers will be much more precise, current, and backed by evidence.\\n\\nDoes that explanation help you **understand** what RAG is and why it\'s such an important development in AI? Can you think of an example where this capability would be really valuable for an AI system?\"}]', '2025-11-03 21:38:50'),
(57, 25, 'user', '[{\"text\":\"Healthcare records\"}]', '2025-11-03 21:41:58'),
(58, 25, 'model', '[{\"text\":\"That\'s an **excellent** example! Healthcare records are a perfect illustration of where RAG (Retrieval-Augmented Generation) becomes incredibly valuable and even critical.\\n\\nLet\'s unpack why:\\n\\n1.  **Factual Accuracy is Paramount**: In healthcare, misinformation or \\\"hallucinations\\\" by an AI can have severe, even life-threatening, consequences. RAG ensures that the AI\'s responses about a patient\'s history, specific drug interactions, or treatment protocols are directly sourced from their verified medical records, clinical guidelines, or evidence-based research.\\n\\n2.  **Highly Specific Domain Knowledge**: Each patient has a unique medical history, medications, allergies, and ongoing conditions. An LLM trained only on general medical texts wouldn\'t know these specifics. RAG allows the AI to *retrieve* and incorporate data directly from an individual patient\'s Electronic Health Record (EHR) before generating a response to a doctor\'s or nurse\'s query about *that specific patient*.\\n\\n3.  **Up-to-Date Information (Guidelines & Research)**: Medical knowledge and best practices evolve constantly. New research emerges, and treatment guidelines are updated. RAG could be used to connect an LLM to the latest peer-reviewed journals, clinical trials databases, or updated organizational policies, ensuring the information provided is current.\\n\\n4.  **Privacy and Security**: RAG allows healthcare providers to leverage powerful LLMs without needing to upload sensitive patient data directly into the LLM\'s core training. The sensitive data stays within the secure, private knowledge base, and only relevant, anonymized (if necessary) snippets are retrieved and used for *context* for a specific query.\\n\\n5.  **Reduced Hallucinations**: Imagine asking an AI about a patient\'s recent lab results. Without RAG, it might invent plausible-sounding numbers. With RAG, it retrieves the *actual* lab report and provides a summary or analysis based on the real data.\\n\\n### How it might work in practice:\\n\\n*   **Doctor\'s Assistant**: A doctor asks, \\\"What were Mrs. Smith\'s blood pressure readings over the last three months, and how do they compare to her target range?\\\" The RAG system would retrieve relevant BP readings from Mrs. Smith\'s EHR, the established target range from her care plan, and then the LLM would summarize this information for the doctor.\\n*   **Clinical Decision Support**: A nurse asks, \\\"What are the latest treatment protocols for sepsis given Mr. Jones\'s specific comorbidities?\\\" The RAG system would pull from the hospital\'s internal, up-to-date clinical guidelines and Mr. Jones\'s specific medical history, allowing the LLM to generate a tailored recommendation.\\n\\nYour example perfectly highlights how RAG bridges the gap between the broad intelligence of an LLM and the need for precision, accuracy, and domain-specific knowledge in high-stakes environments.\\n\\nThinking about this application in healthcare, what do you see as some of the biggest **challenges** or considerations when implementing RAG with sensitive data like medical records?\"}]', '2025-11-03 21:42:06'),
(59, 25, 'user', '[{\"text\":\"Can I make mention of biases and hallucinations?\"}]', '2025-11-03 21:43:12');
INSERT INTO `messages` (`id`, `conversation_id`, `role`, `content`, `created_at`) VALUES
(60, 25, 'model', '[{\"text\":\"Absolutely, **yes!** Biases and hallucinations are incredibly important considerations and represent significant challenges when implementing RAG, especially with sensitive data like healthcare records. That\'s a very insightful point.\\n\\nLet\'s break down why:\\n\\n### 1. Biases\\n\\nWhile RAG aims to ground LLMs in factual data, it doesn\'t automatically eliminate bias. Here\'s how bias can still creep in:\\n\\n*   **Bias in the Retrieval Corpus**: If the external knowledge base (e.g., medical journals, clinical guidelines, patient records) itself contains historical biases, the RAG system will retrieve and amplify them.\\n    *   **Example**: Historically, medical research has sometimes underrepresented certain demographics. If an AI relies heavily on this biased research, it might retrieve and present information that leads to less accurate diagnoses or treatment recommendations for those underrepresented groups.\\n    *   **Example**: If patient records in a database reflect systemic biases in how certain communities receive care (e.g., delayed treatment, less thorough examinations), the RAG system might inadvertently perpetuate these patterns by drawing from this biased \\\"real-world\\\" data.\\n*   **Bias in the Search Algorithm**: The way the system decides *what* information is \\\"relevant\\\" to retrieve can also be biased. If the algorithm is subtly tuned to prioritize certain types of information or sources over others, it could lead to skewed results.\\n*   **Bias in the LLM\'s Interpretation**: Even with perfect retrieved context, the underlying LLM still interprets that information. If the LLM itself has inherent biases from its pre-training, it might subtly misinterpret or place undue emphasis on certain parts of the retrieved data, leading to a biased generated response.\\n\\n### 2. Hallucinations\\n\\nRAG significantly *reduces* hallucinations by providing a factual grounding, but it doesn\'t eliminate them entirely. Here\'s why:\\n\\n*   **Synthesizing Information**: The LLM\'s job isn\'t just to parrot the retrieved text; it\'s to *synthesize* and *generate* a coherent answer based on that text and its general knowledge. In this synthesis process, there\'s still a risk of making connections or inferences that aren\'t fully supported by the retrieved data, leading to a subtle form of hallucination.\\n*   **Insufficient or Ambiguous Context**: If the retriever doesn\'t find enough relevant information, or if the retrieved information is contradictory or ambiguous, the LLM might still \\\"fill in the gaps\\\" with its own generalized (and potentially incorrect) knowledge, effectively hallucinating.\\n*   **Misinterpretation of Retrieved Data**: The LLM might misinterpret a specific nuance in the retrieved medical text, leading to an incorrect conclusion that appears to be based on the data but isn\'t.\\n\\nIn healthcare, where decisions have profound impacts on human lives, these challenges are amplified. Ensuring that RAG systems are not only accurate but also fair and transparent is a monumental task.\\n\\nDo you have any thoughts on how one might try to **mitigate** or address these issues of bias and residual hallucination in a RAG system for healthcare?\"}]', '2025-11-03 21:43:20'),
(61, 25, 'user', '[{\"text\":\"I can\'t think of any\"}]', '2025-11-03 21:44:43'),
(62, 25, 'model', '[{\"text\":\"That\'s perfectly normal \\u2013 these are complex problems that AI researchers and engineers are actively working on! It\'s challenging because it touches on both technical solutions and ethical considerations.\\n\\nLet\'s break it down. When we think about mitigating problems, we often look at the different stages of the system. For RAG, we have:\\n\\n1.  **The Knowledge Base \\/ Corpus** (where the information is retrieved from)\\n2.  **The Retrieval Process** (how relevant information is found)\\n3.  **The LLM\'s Generation Process** (how the answer is formed using the retrieved info)\\n\\nLet\'s take **bias** first. If the problem often starts with the *data*, what could we do about the data itself or how we use it, to make it less biased? Think about the sources we mentioned \\u2013 medical journals, patient records, guidelines. How can we make sure these sources are as fair as possible?\"}]', '2025-11-03 21:44:48'),
(63, 25, 'user', '[{\"text\":\"the data shouldn\'t come from just one geographical region\"}]', '2025-11-03 21:47:34'),
(64, 25, 'model', '[{\"text\":\"That\'s an **excellent point** and a very practical way to start!\\n\\nYou\'re absolutely right:\\n\\n### 1. Mitigating Bias: Diversifying the Knowledge Base\\n\\nIf the data comes from just one geographical region (e.g., healthcare records only from a specific hospital system in one country, or research predominantly from a single academic institution), it\'s highly likely to reflect the demographics, cultural norms, and even prevalent diseases and treatment approaches of that specific region. This can lead to biased advice or diagnoses when applied to patients from other regions.\\n\\n**By diversifying the data geographically**, we aim to:\\n\\n*   **Improve Representativeness**: Include data from diverse patient populations, which can reflect variations in genetics, lifestyle, environmental factors, and disease prevalence across different regions.\\n*   **Account for Varied Healthcare Practices**: Different countries and regions have different healthcare systems, guidelines, and treatment availabilities. A RAG system trained on a broader dataset would be better equipped to provide relevant information globally.\\n*   **Reduce Systemic Bias**: Over-reliance on data from a region with known historical health disparities could perpetuate those disparities. Broadening the scope helps to counterbalance this.\\n\\nThis is a fantastic first step for addressing bias.\\n\\nWhat other kinds of **diversity** might be important in the healthcare data itself, beyond just geographical? Or, what else could we do to the *knowledge base* to make it less biased?\"}]', '2025-11-03 21:47:39'),
(65, 25, 'user', '[{\"text\":\"I can\'t think of anything else\"}]', '2025-11-03 21:48:16'),
(66, 25, 'model', '[{\"text\":\"No worries at all, it\'s a deep topic! Let\'s consider another aspect of \\\"diversity\\\" in the data, thinking specifically about the *people* represented in healthcare records or research.\\n\\nBeyond just *where* the data comes from, what about *who* the data represents? Are there other groups of people that might be underrepresented or whose experiences might be overlooked if the data isn\'t carefully curated?\\n\\nThink about different demographics or characteristics that might be important in health.\"}]', '2025-11-03 21:48:19'),
(67, 25, 'user', '[{\"text\":\"That seems to be the case\"}]', '2025-11-03 21:48:59'),
(68, 25, 'model', '[{\"text\":\"You\'re absolutely right, it often is the case!\\n\\nWhen we think about \\\"who the data represents\\\" in healthcare, we\'re talking about **demographic diversity**. Beyond just geography, medical data can often be lacking or skewed for various groups.\\n\\nCan you think of any specific characteristics or groups of people that are sometimes not adequately represented in medical studies or patient databases, and why that might be a problem for an AI trying to provide good care? Think about things like:\\n\\n*   **Biological factors**\\n*   **Social factors**\\n*   **Economic factors**\\n\\nNo need to be exhaustive, just whatever comes to mind!\"}]', '2025-11-03 21:49:02'),
(69, 25, 'user', '[{\"text\":\"race, available technology to access these records\"}]', '2025-11-03 21:50:07'),
(70, 25, 'model', '[{\"text\":\"Excellent, those are two very insightful and critical points!\\n\\n### 1. **Race\\/Ethnicity** (Demographic Diversity)\\n\\nYou\'re spot on that **race and ethnicity** are crucial factors for diversity in healthcare data.\\n\\n*   **Why it\'s a problem:** Medical conditions, drug responses, and disease prevalence can vary significantly across different racial and ethnic groups. Historically, medical research has often focused on specific populations (e.g., predominantly white males), leading to a lack of understanding or misapplication of findings to other groups. If a RAG system primarily retrieves information from such biased research, it could:\\n    *   Fail to recognize specific symptoms or risk factors in certain ethnic groups.\\n    *   Recommend treatments that are less effective or have more side effects for particular racial backgrounds due to genetic variations in drug metabolism.\\n    *   Perpetuate health disparities by not reflecting the full spectrum of human health.\\n*   **Mitigation Strategy:** Actively seek out and include medical literature, clinical trial data, and patient records that are **diverse across racial and ethnic lines**. This requires conscious effort in data collection and curation to ensure representation.\\n\\n### 2. **Available Technology to Access Records** (Data Accessibility & Socioeconomic Factors)\\n\\nThis points to a broader issue of **socioeconomic factors and digital divides**.\\n\\n*   **Why it\'s a problem:**\\n    *   **Data Completeness & Quality**: If certain populations have limited access to technology (e.g., smartphones, internet) or high-quality healthcare facilities, their medical records might be less complete, less digitized, or contain less detailed information. A RAG system relying on this data might have an incomplete picture for these individuals.\\n    *   **Bias in Data Collection**: The *way* data is collected might also be biased. For example, if a health system primarily uses patient portals for data input, individuals without consistent internet access might be underrepresented or inaccurately represented.\\n    *   **Accessibility of the AI System Itself**: Beyond the data, if the RAG-powered AI is primarily accessed through high-tech interfaces, it could inadvertently exclude healthcare providers or patients in settings with limited technological infrastructure.\\n*   **Mitigation Strategy:**\\n    *   **Focus on Comprehensive Data Collection**: Ensure that data collection methods are inclusive and robust across all patient demographics, not just those with easy access to technology. This might mean investing in manual entry for paper records, or using diverse methods of patient engagement.\\n    *   **Address Data Gaps**: Actively identify and work to fill gaps in data for underserved populations.\\n    *   **Consider the \\\"Cold Start\\\" Problem**: For new patients from underrepresented groups, where less data exists, the RAG system might need to rely more heavily on general medical knowledge, while carefully flagging its uncertainty.\\n\\nYou\'ve really hit on some fundamental challenges! We\'ve discussed how to address bias by diversifying the *knowledge base* itself.\\n\\nNow, let\'s switch gears to the other main issue you raised: **hallucinations**. Even with a great, diverse knowledge base, how can we try to reduce the chances of the LLM still \\\"making things up\\\" or misinterpreting the retrieved information?\\n\\nThink about the process: the RAG system *retrieves* information, and then the LLM *generates* an answer. What steps could we take in those two parts of the process to minimize hallucinations?\"}]', '2025-11-03 21:50:13'),
(71, 25, 'user', '[{\"text\":\"I would say continually train new data to an LLM but it can be computationally expensive. So I suggest a separate system that does the verification\"}]', '2025-11-03 21:52:25'),
(72, 25, 'model', '[{\"text\":\"Those are both excellent thoughts and point towards two different, valid strategies for reducing hallucinations!\\n\\n### 1. **Continually Training New Data to an LLM**\\n\\nYou\'re absolutely right that this is a way to update an LLM\'s knowledge base and reduce the need for it to \\\"guess\\\" about new information.\\n*   **Pros**: Directly updates the LLM\'s internal knowledge, potentially reducing hallucinations for frequently updated common knowledge.\\n*   **Cons**: As you noted, it\'s **computationally expensive and time-consuming** (requiring full retraining or fine-tuning), and it still won\'t cover *every* piece of specific, private, or real-time data like an individual patient\'s EHR. This is exactly why RAG was developed in the first place \\u2013 to avoid constant retraining for new, evolving, or domain-specific information. So, while valid, it\'s not the primary RAG solution for *this specific problem*.\\n\\n### 2. **A Separate System for Verification**\\n\\nThis is a very powerful and practical idea! This falls under the concept of **\\\"fact-checking\\\" or \\\"post-generation validation.\\\"**\\n\\n*   **How it works**: After the RAG system generates a response, a secondary verification module (which could be another AI, a rule-based system, or even a human-in-the-loop) checks the generated answer against the retrieved sources and\\/or other trusted knowledge.\\n*   **Example**: If the RAG system says, \\\"Patient X has an allergy to Penicillin, according to their record,\\\" the verifier could specifically check that statement against the retrieved snippet from the patient\'s record to ensure direct textual support. If the RAG system says, \\\"The standard dosage for drug Y is 10mg,\\\" the verifier could check a separate drug database.\\n*   **Pros**: Adds a layer of security, helps catch subtle hallucinations or misinterpretations, and can improve trustworthiness.\\n*   **Cons**: Can add latency (slow down the response), and designing a robust, general-purpose verifier is also complex.\\n\\nThis is a fantastic strategy. To build on this idea of verification and accountability, let\'s think about **transparency**. If an AI *does* make a claim, how can we help the user (like a doctor) quickly see if that claim is based on solid evidence or if it might be a hallucination? What information could the RAG system provide alongside its answer?\"}]', '2025-11-03 21:52:30'),
(73, 25, 'user', '[{\"text\":\"help me out on this\"}]', '2025-11-03 21:55:43'),
(74, 25, 'model', '[{\"text\":\"No problem at all, let\'s think about this together!\\n\\nImagine you\'re a doctor, and the RAG system tells you \\\"Patient X should not be given Drug Y because of a known kidney issue.\\\" As a doctor, what would be the first thing you\'d want to see or know to trust that statement and verify it quickly?\\n\\nWould you just take the AI\'s word for it, or would you want to know *where* it got that information?\\n\\nThink about how you\'d cite sources in an essay or report. What\'s similar here?\"}]', '2025-11-03 21:55:45'),
(75, 25, 'user', '[{\"text\":\"Inclusion of the source of its answer\"}]', '2025-11-03 21:56:34'),
(76, 25, 'model', '[{\"text\":\"Exactly! You\'ve hit on a crucial point for transparency and trust: **Inclusion of the source of its answer.**\\n\\nThis is often called **source attribution** or **citation**.\\n\\n### 3. Mitigating Hallucinations: Source Attribution\\n\\n*   **How it works**: The RAG system doesn\'t just provide an answer; it also provides the specific document, paragraph, or even sentence from its knowledge base that supports each key piece of information in its response.\\n*   **Example**: Instead of just saying \\\"Patient X has a penicillin allergy,\\\" the system might say: \\\"Patient X has a penicillin allergy (Source: EHR, Allergy Section, dated 2023-05-10).\\\" Or it might even link directly to the relevant section of a clinical guideline.\\n*   **Pros**:\\n    *   **Verifiability**: Users (like doctors) can quickly check the original source to confirm the accuracy of the AI\'s statement. This is incredibly important in high-stakes fields like healthcare.\\n    *   **Trust and Confidence**: Knowing that the AI\'s answer is grounded in specific, retrievable evidence builds user trust.\\n    *   **Debugging\\/Understanding**: If an answer seems off, the source attribution helps identify if the problem was in the retrieval (wrong source found), the generation (misinterpreted source), or even a problem with the source itself.\\n    *   **Reduces Perceived Hallucinations**: Even if the LLM subtly misinterprets something, the user can immediately see the source and potentially correct their understanding, rather than just taking the AI\'s potentially flawed word for it.\\n\\n### Other Strategies to Mitigate Hallucinations (Briefly):\\n\\n*   **Improve Retrieval Accuracy**: Enhance the search algorithms so they consistently pull the *most* relevant and *least* ambiguous information. This is a continuous area of research.\\n*   **Prompt Engineering**: Carefully design the prompt to the LLM, instructing it to only use the provided context and explicitly state if the answer cannot be found in the given sources. For example, \\\"Using ONLY the provided medical records, answer the following question. If the information is not present, state \'Information not found in records.\'\\\"\\n*   **Confidence Scoring**: Have the system express a confidence level for its answer, especially when the retrieved information is sparse or contradictory. This alerts the user to potentially less reliable answers.\\n\\nYou\'ve done a fantastic job identifying key strategies for both bias and hallucinations in RAG systems for healthcare!\\n\\nJust to recap, for **mitigating bias**, we discussed:\\n*   Diversifying the geographical origin of the data.\\n*   Ensuring demographic diversity (e.g., race\\/ethnicity, socioeconomic factors) in the patient data and research.\\n\\nAnd for **mitigating hallucinations**, we discussed:\\n*   Using a separate system for post-generation verification.\\n*   Including source attribution in the AI\'s answers for transparency.\\n\\nDoes this comprehensive discussion give you a solid **understanding** of RAG, its benefits, and its crucial challenges and potential solutions, especially in a sensitive domain like healthcare?\"}]', '2025-11-03 21:56:40'),
(77, 25, 'user', '[{\"text\":\"Indeed, I have a fair idea\"}]', '2025-11-03 22:08:21'),
(78, 25, 'model', '[{\"text\":\"That\'s great to hear! I\'m glad we could explore RAG (Retrieval-Augmented Generation) in depth, covering its core function, its immense benefits, and the critical challenges like bias and hallucinations, especially within the context of healthcare.\\n\\nYou\'ve really grasped some complex concepts and even came up with some excellent mitigation strategies yourself!\\n\\nTo solidify your understanding, perhaps you could consider one more thing:\\n\\nIf you were a developer building a RAG system for a new **non-healthcare** domain (e.g., legal, finance, customer support), what would be the **first thing** you\'d think about regarding bias or hallucination based on what we\'ve discussed today?\"}]', '2025-11-03 22:08:24'),
(79, 26, 'user', '[{\"text\":\"Anscombes quarter\"}]', '2025-11-03 22:08:43'),
(80, 26, 'model', '[{\"text\":\"That\'s a great concept to explore! Anscombe\'s Quartet is a classic example in statistics and data analysis that beautifully illustrates a crucial point about data.\\n\\nIn simple terms, **Anscombe\'s Quartet** is a set of **four different datasets** that, when analyzed using basic statistical measures, appear almost identical. For instance, all four datasets have:\\n\\n*   The same mean of the x-values\\n*   The same mean of the y-values\\n*   The same variance of the x-values\\n*   The same variance of the y-values\\n*   The same correlation coefficient between x and y\\n*   The same linear regression line\\n\\nHowever, when you **visualize** these four datasets by plotting them on a graph, they look remarkably different! Each dataset tells a unique story and displays a distinct relationship (or lack thereof) between its x and y variables.\\n\\n**Why is it important?**\\nAnscombe\'s Quartet is a powerful reminder that relying solely on summary statistics (like mean, variance, or correlation) can be misleading. It highlights the absolute necessity of **visualizing your data** before drawing conclusions or building models.\\n\\nWithout seeing the plots, you might incorrectly assume that all four datasets exhibit the same kind of relationship. But a quick glance at their graphs reveals:\\n\\n1.  One dataset shows a clear linear relationship.\\n2.  Another shows a curvilinear relationship.\\n3.  A third has a perfect linear relationship, but with an outlier skewing the statistics.\\n4.  The fourth shows no clear relationship, with one extreme outlier pulling the regression line.\\n\\nIt teaches us that **\\\"the numbers don\'t tell the whole story.\\\"** Always look at your data!\\n\\nDoes that initial explanation help you understand what Anscombe\'s Quartet is about? Would you like to explore what each of those four datasets looks like, or perhaps discuss its implications further?\"}]', '2025-11-03 22:08:52'),
(81, 27, 'user', '[{\"text\":\"What is anscombes quartet and how can I apply it in a graph\"}]', '2025-11-03 22:17:39'),
(82, 27, 'model', '[{\"text\":\"That\'s a fantastic question that gets right to the heart of understanding data! Anscombe\'s Quartet is a classic and very powerful demonstration in statistics.\\n\\nLet\'s break down what it is and how you can \\\"apply\\\" its lesson when you\'re working with graphs.\\n\\n### What is Anscombe\'s Quartet?\\n\\nAnscombe\'s Quartet is a set of **four distinct datasets** that each comprise 11 `(x, y)` data points. The remarkable thing about these four datasets is that they all have nearly identical **basic descriptive statistics**, such as:\\n\\n*   **Mean** of `x` values\\n*   **Variance** of `x` values\\n*   **Mean** of `y` values\\n*   **Variance** of `y` values\\n*   **Correlation coefficient** between `x` and `y`\\n*   **Linear regression line** (the line of best fit)\\n\\nDespite these identical summary statistics, when you plot each dataset on a scatter graph, they look **drastically different** and reveal very different underlying relationships between `x` and `y`.\\n\\nThe main takeaway from Anscombe\'s Quartet is a crucial lesson:\\n\\n**Always visualize your data! Relying solely on summary statistics can be incredibly misleading and cause you to misinterpret relationships or miss important features like outliers or non-linear patterns.**\\n\\n### How Can You \\\"Apply\\\" It In a Graph?\\n\\nYou don\'t \\\"apply\\\" Anscombe\'s Quartet as a technique *to* a graph; rather, it teaches you a **fundamental principle** that you should apply *every time* you work with graphs and data:\\n\\n1.  **Don\'t Trust Numbers Alone:** If someone gives you a table of means, variances, and correlations for a dataset (or multiple datasets), that\'s a good start, but it\'s **never enough**. Anscombe\'s Quartet shows that these numbers can hide vastly different realities.\\n2.  **Always Create a Visual:** Before drawing any conclusions about the relationship between variables, you **must create a visual representation**, typically a scatter plot for two continuous variables. This allows you to:\\n    *   **Identify the true nature of the relationship:** Is it linear, curvilinear (like a parabola), or something else entirely?\\n    *   **Detect outliers:** Are there data points that don\'t fit the general pattern and might be skewing your statistics?\\n    *   **Spot unusual patterns:** Are there clusters, gaps, or other features that summary statistics would never reveal?\\n\\n**Let\'s look at the four datasets conceptually to see what I mean:**\\n\\n*   **Dataset I:** Shows a clear, positive linear relationship, exactly what you\'d expect from the summary statistics.\\n*   **Dataset II:** Shows a curvilinear (parabolic) relationship. The `x` and `y` values increase together, but not in a straight line. If you just looked at the correlation coefficient, you\'d think it was linear!\\n*   **Dataset III:** Shows a strong linear relationship, but with a single extreme outlier that significantly influences the linear regression line. Remove that one point, and the line would be very different.\\n*   **Dataset IV:** Shows points clustered along a vertical line, with a single outlier point far to the right. This single outlier is what drives the correlation and the regression line, making it appear as if there\'s a linear relationship where there really isn\'t one for most of the data.\\n\\n**In essence, applying the lesson of Anscombe\'s Quartet means adopting a habit of graphical exploration as a non-negotiable first step in data analysis.** It\'s about remembering that the same numbers can tell wildly different stories.\\n\\nDoes this explanation help you understand why visual inspection of data is so crucial alongside numerical summaries?\"}]', '2025-11-03 22:17:53'),
(83, 28, 'user', '[{\"text\":\"What is anscombes quartet and how do I apply it in a graph\"}]', '2025-11-03 22:18:30'),
(84, 28, 'model', '[{\"text\":\"That\'s a fantastic question, and Anscombe\'s Quartet is a really insightful concept for anyone working with data! It\'s one of those ideas that fundamentally shifts how you think about data analysis and the importance of visualization.\\n\\n### What is Anscombe\'s Quartet?\\n\\nAnscombe\'s Quartet is a collection of **four different datasets** that all share nearly identical **summary statistics**. What does that mean? It means if you calculate common descriptive statistics for each of the four datasets, such as:\\n\\n*   The mean of the x-values\\n*   The variance of the x-values\\n*   The mean of the y-values\\n*   The variance of the y-values\\n*   The correlation coefficient between x and y\\n*   The equation of the linear regression line\\n\\n...you\'ll find these values are almost exactly the same for all four datasets.\\n\\nHowever, and this is the crucial part, when you **plot each dataset on a graph**, they look dramatically different. This is its core message: **summary statistics alone can be incredibly misleading, and visualizing your data is absolutely essential before drawing conclusions.**\\n\\n### How do I \\\"apply\\\" it in a graph?\\n\\nYou don\'t \\\"apply\\\" Anscombe\'s Quartet *to* a graph in the sense of a technique or a function. Instead, Anscombe\'s Quartet is a **demonstration** that teaches you *why* you must always graph your data. It applies to *your approach* to data analysis, not directly *to* the graph itself.\\n\\nWhen you graph the four datasets, here\'s what you typically observe:\\n\\n1.  **Dataset I:** Looks like a standard linear relationship with some scatter. This is often what we expect when we see a strong correlation.\\n2.  **Dataset II:** Shows a clear curvilinear (non-linear) relationship. A linear regression line would look like a poor fit for this data, despite having the same linear correlation coefficient as Dataset I.\\n3.  **Dataset III:** Has a perfect linear relationship for most points, but with a single extreme **outlier** pulling the regression line upwards. If you removed that one point, the line would change drastically.\\n4.  **Dataset IV:** Features a constant x-value for almost all points, and then one single outlier with a very different x-value that dictates the entire linear regression line. Without that specific outlier, you\'d have no slope, or an undefined slope (as all other x-values are the same).\\n\\n**In essence, Anscombe\'s Quartet is a powerful cautionary tale for data analysts, highlighting these key principles for your graphical work:**\\n\\n*   **Always plot your data!** Before drawing any conclusions from summary statistics or fitting models, visualize your data to understand its underlying structure.\\n*   **Look beyond the numbers.** The \\\"shape\\\" or pattern of the data on a scatter plot tells you far more than just the mean, variance, or correlation coefficient.\\n*   **Be aware of outliers.** Outliers can heavily influence summary statistics and regression lines, as vividly seen in datasets III and IV.\\n*   **Choose appropriate models.** A high correlation doesn\'t always mean a linear model is the best fit, as demonstrated by Dataset II.\\n\\nDoes that explanation clarify what Anscombe\'s Quartet is and why it\'s so important in the context of how you approach data visualization?\"}]', '2025-11-03 22:18:44'),
(85, 28, 'user', '[{\"text\":\"No\"}]', '2025-11-03 22:18:53'),
(86, 28, 'model', '[{\"text\":\"Thanks for letting me know! That helps me understand where we need to adjust.\\n\\nIt\'s common for this concept to be a bit tricky at first, because it challenges our intuition about data.\\n\\nCould you tell me which part felt unclear? For example, was it:\\n\\n1.  **What \\\"summary statistics\\\" are** (like averages, correlation)?\\n2.  **The idea that different datasets can have the *same* statistics but look *different*?**\\n3.  **Or the \\\"how to apply it in a graph\\\" part?** (Maybe it\'s still not clear that it\'s a *lesson* about graphing, not something you *do* to a graph).\\n\\nKnowing what specifically wasn\'t clicking will help me explain it in a different way!\\n\\nLet\'s try thinking about it with a simpler analogy while you consider the above:\\n\\nImagine you have four different houses.\\n*   You measure the **average height of the people** in each house.\\n*   You measure the **average number of rooms** in each house.\\n*   You measure the **average age of the occupants** in each house.\\n\\nWhat if all four houses gave you nearly the **exact same averages** for all these things? You might think, \\\"Oh, these houses are all pretty similar!\\\"\\n\\nBut then, you **look at pictures** of the houses:\\n*   House 1 is a regular family home.\\n*   House 2 is a long, skinny house with a curved roof.\\n*   House 3 is a tiny cottage, but with one gigantic tower stuck on top.\\n*   House 4 is a row of small identical apartments, but with one huge mansion next door.\\n\\nEven though their **averages were the same**, looking at the pictures (the \\\"graphs\\\") shows you they are vastly, dramatically different, and that your initial thought of \\\"they\'re similar\\\" was wrong.\\n\\nAnscombe\'s Quartet is just like this, but with numbers and data points instead of houses. It\'s a vivid demonstration that **just looking at the numbers (statistics) isn\'t enough; you *must* look at the picture (the graph) to truly understand what\'s going on.**\\n\\nDoes that analogy help bridge the gap at all? Or can you pinpoint what exactly made you say \\\"No\\\" to the previous explanation? No worries at all, we\'ll get there!\"}]', '2025-11-03 22:19:04'),
(87, 28, 'user', '[{\"text\":\"Explain further\"}]', '2025-11-03 22:19:36'),
(88, 28, 'model', '[{\"text\":\"Okay, absolutely, let\'s break it down further! Sometimes these concepts click best with a few different angles.\\n\\nLet\'s start with the absolute core idea of Anscombe\'s Quartet again, and then we\'ll dive into *why* it works that way and what it truly means for you.\\n\\n### The Core Idea, Simply Put\\n\\nImagine you have four different \\\"stories\\\" told by data.\\nFor each of these four stories, if you just read the \\\"summary\\\" (the statistics like average, correlation), all four summaries would sound almost identical. You\'d think, \\\"Oh, these four stories are basically the same!\\\"\\n\\nBut then, if you actually **look at the full picture** of each story (the graph), you\'d be shocked. They are incredibly, dramatically different.\\n\\n**Anscombe\'s Quartet is the proof that the \\\"summary\\\" (statistics) can lie to you, and the \\\"full picture\\\" (graph) tells the truth.**\\n\\n---\\n\\n### Why the Statistics Can Be Misleading (The \\\"How\\\" of Anscombe\'s Quartet)\\n\\nLet\'s focus on one key statistic: **correlation**. Correlation tells you how strongly two variables (like `x` and `y`) move together, and in what direction (positive or negative). A correlation close to `1` or `-1` means a strong linear relationship.\\n\\nFor all four datasets in Anscombe\'s Quartet, the correlation coefficient between `x` and `y` is approximately **0.816**. This is a fairly strong positive correlation, suggesting a nice, upward-sloping linear trend.\\n\\nNow, let\'s imagine what this *should* mean for each dataset if we only looked at the numbers:\\n\\\"Okay, x goes up, y tends to go up, and it\'s a pretty strong, consistent pattern.\\\"\\n\\n**But here\'s why that\'s wrong without the graph:**\\n\\n*   **Dataset I (The \\\"Normal\\\" One):**\\n    *   **Graph:** Shows points scattered relatively evenly around an upward-sloping straight line.\\n    *   **Why stat works:** The data genuinely follows a linear pattern. The correlation of 0.816 accurately describes this. This is what we usually hope for.\\n\\n*   **Dataset II (The Curved One):**\\n    *   **Graph:** Shows points following a distinct **curved path** (like a parabola), not a straight line.\\n    *   **Why stat is misleading:** Even though the points follow a strong pattern, that pattern isn\'t *linear*. A straight line drawn through this data would look like a poor fit, even with a correlation of 0.816. The correlation only measures *linear* relationship, and here, there\'s a strong *non-linear* relationship. If you tried to make predictions with a straight line, they would be very inaccurate for most of the data points.\\n\\n*   **Dataset III (The Outlier Pull):**\\n    *   **Graph:** Almost all points are perfectly lined up in a straight line, but there\'s **one single point way off by itself** (an \\\"outlier\\\").\\n    *   **Why stat is misleading:** That one distant outlier point is pulling the entire correlation and the regression line towards itself. Without that single point, the remaining data would show an even stronger, almost perfect linear correlation. The 0.816 correlation is heavily influenced by that one unusual data point, making the relationship appear less strong (or different) than it is for the *majority* of the data.\\n\\n*   **Dataset IV (The Influential Outlier):**\\n    *   **Graph:** All the `x` values are the same for almost all points, except for **one single point** that has a very different `x` value.\\n    *   **Why stat is misleading:** If you removed that one unusual point, all other points would have the same `x` value. You wouldn\'t be able to calculate a linear correlation or a regression line in the usual way (you\'d essentially have a vertical line of points). It\'s *only* because of that one specific, isolated point that a correlation (0.816) and a linear regression line can even be calculated and appear to fit. That single point entirely determines the perceived relationship.\\n\\n---\\n\\n### How to \\\"Apply\\\" It in a Graph (The Lesson, Not a Technique)\\n\\nYou are right to ask about \\\"applying it in a graph.\\\" It\'s not a step you take like \\\"apply filter\\\" or \\\"apply formula.\\\" Instead, it\'s a **fundamental rule or principle that should guide your every action when working with graphs and data.**\\n\\n**Think of it as the \\\"Prime Directive\\\" for data analysis:**\\n\\n1.  **Before you ever calculate *any* summary statistic** (mean, correlation, variance, etc.)...\\n2.  **Before you ever try to fit *any* model** (linear regression, non-linear model, etc.)...\\n3.  **YOU MUST ALWAYS GRAPH YOUR DATA FIRST!**\\n\\nAnscombe\'s Quartet gives you **four concrete examples** of *why* this rule is so vital. If you didn\'t graph those four datasets, you\'d think they were all basically the same. But once you graph them, you immediately see:\\n\\n*   \\\"Ah, Dataset I looks good for a linear model.\\\"\\n*   \\\"Wait, Dataset II is clearly curved; I shouldn\'t use a straight line here.\\\"\\n*   \\\"Look at Dataset III! That one point is messing everything up. I need to investigate it.\\\"\\n*   \\\"Wow, Dataset IV\'s entire relationship hinges on just one point. This isn\'t a general trend at all.\\\"\\n\\n**So, when you \\\"apply Anscombe\'s Quartet,\\\" you are essentially applying its lesson:**\\n\\n*   **You\'re making a scatter plot** (or other appropriate graph) as a standard first step in your analysis.\\n*   **You\'re critically examining the visual patterns** in your graph.\\n*   **You\'re questioning whether your summary statistics or chosen models actually make sense** in light of what the graph is showing you.\\n*   **You\'re looking for outliers or non-linear patterns** that simple numbers might hide.\\n\\nIt\'s a call to **visual literacy** in data analysis. Don\'t trust the numbers blindly; let your eyes confirm (or refute) what the numbers are suggesting.\\n\\nDoes explaining the misleading nature of the statistics for each case, and framing the \\\"application\\\" as a mandatory first step of visualizing your data, help clarify things further?\"}]', '2025-11-03 22:19:49'),
(89, 29, 'user', '[{\"text\":\"Explain Anscombe\\u2019s quartet\"}]', '2025-11-03 22:23:30'),
(90, 29, 'model', '[{\"text\":\"That\'s an excellent concept to understand! Anscombe\'s Quartet is a powerful illustration in statistics that highlights the critical importance of visualizing your data, rather than relying solely on summary statistics.\\n\\nAt its core, **Anscombe\'s Quartet** refers to **four datasets that have nearly identical simple descriptive statistics**, such as:\\n\\n*   Mean of x\\n*   Variance of x\\n*   Mean of y\\n*   Variance of y\\n*   Correlation between x and y\\n*   The linear regression line\\n\\nHowever, when you **plot these four datasets visually**, they appear dramatically different and reveal very distinct relationships between the variables.\\n\\n### The Four Datasets\\n\\nLet me describe the general characteristics of each dataset when plotted:\\n\\n1.  **Dataset I:** This looks like a fairly standard, positive linear relationship, with the data points scattered roughly around a line. This is the dataset most people would expect if they only saw the summary statistics.\\n2.  **Dataset II:** This dataset shows a clear **curvilinear relationship** (a curve), not a linear one. While the linear regression line fits it statistically, it completely misrepresents the true underlying pattern of the data.\\n3.  **Dataset III:** This one looks like a strong linear relationship, but with a **single outlier** that significantly influences the regression line. Without that outlier, the relationship would look very different, or perhaps there\'d be no clear linear trend at all.\\n4.  **Dataset IV:** This dataset shows a horizontal line of data points, except for one **high-leverage point** that is far to the right and dictates the slope of the regression line. Essentially, almost all the variance in the x-values comes from this single point, and it\'s the only reason a positive linear relationship is suggested.\\n\\n### Why Is It So Important?\\n\\nAnscombe\'s Quartet, developed by statistician Francis J. Anscombe in 1973, teaches us several crucial lessons:\\n\\n1.  **Summary Statistics Can Be Misleading:** Relying only on measures like means, variances, and correlation coefficients can hide very different underlying data structures.\\n2.  **Always Visualize Your Data:** Plotting your data is an essential first step in any data analysis. It allows you to spot patterns, outliers, and non-linear relationships that statistics alone would miss.\\n3.  **Different Relationships, Same Numbers:** It demonstrates that very different phenomena can produce the same statistical summaries.\\n4.  **Avoid Type II Errors (or similar pitfalls):** If you blindly apply a linear model to Dataset II, for example, you\'d be making a poor inference about the true relationship.\\n\\nIn essence, Anscombe\'s Quartet is a powerful reminder that \\\"seeing is believing\\\" when it comes to data.\\n\\nDoes this explanation help you understand the core idea behind Anscombe\'s Quartet and why it\'s so significant in data analysis?\"}]', '2025-11-03 22:23:39'),
(91, 29, 'user', '[{\"text\":\"It\\u2019s still abstract \"}]', '2025-11-03 22:25:00'),
(92, 29, 'model', '[{\"text\":\"You\'re absolutely right to point that out! It\'s easy for statistical concepts to feel abstract until you see them in action. Let\'s make it more concrete.\\n\\nImagine you\'re trying to describe four different people based only on their height and weight averages, and then you see their actual photos. That\'s a bit like Anscombe\'s Quartet.\\n\\nHere\'s the key: All four of Anscombe\'s datasets share these almost identical summary statistics:\\n\\n*   **Average of X values:** Approximately \\\\(9.0\\\\)\\n*   **Variance of X values:** Approximately \\\\(11.0\\\\)\\n*   **Average of Y values:** Approximately \\\\(7.5\\\\)\\n*   **Variance of Y values:** Approximately \\\\(4.1\\\\)\\n*   **Correlation Coefficient (how strongly X and Y are linearly related):** Approximately \\\\(0.816\\\\)\\n*   **The Best-Fit Linear Regression Line (equation of the straight line that fits the data):** \\\\(Y = 0.5X + 3\\\\)\\n\\nNow, if you only saw those numbers, you\'d probably conclude, \\\"Okay, these four datasets are pretty much the same. They all show a moderate positive linear relationship.\\\"\\n\\n### The \\\"Aha!\\\" Moment: Visualizing the Data\\n\\nBut here\'s where it gets wild. Let\'s imagine what each dataset *actually looks like* when plotted on a graph, despite having those identical numbers:\\n\\n1.  **Dataset I: The \\\"Normal\\\" One**\\n    *   **Plot:** This looks exactly like what you\'d expect from the numbers. The points are scattered in a roughly elliptical cloud, centered around the linear regression line (\\\\(Y = 0.5X + 3\\\\)).\\n    *   **What it means:** The summary statistics (mean, variance, correlation, regression line) accurately describe this data.\\n\\n2.  **Dataset II: The \\\"Curvy\\\" One**\\n    *   **Plot:** Imagine a perfect parabola (a \\\"U\\\" shape) or a curve. All the data points fall neatly along this curve.\\n    *   **What it means:** Even though the regression line \\\\(Y = 0.5X + 3\\\\) is calculated to be the \\\"best fit\\\" straight line, it completely misrepresents the data! The true relationship is clearly non-linear. If you only looked at the numbers, you\'d think it\'s linear.\\n\\n3.  **Dataset III: The \\\"Outlier Problem\\\"**\\n    *   **Plot:** Most of the data points are clustered in a straight line, but there\'s **one single point way off by itself** (an outlier). This one outlier is so powerful it pulls the entire regression line toward it, making it look like there\'s a linear relationship when, for most of the data, there might not be or it might be different.\\n    *   **What it means:** The summary statistics are heavily influenced by that one rogue data point. If you removed that single point, the correlation would probably vanish or change dramatically.\\n\\n4.  **Dataset IV: The \\\"Leverage Point\\\"**\\n    *   **Plot:** Almost all the data points are stacked up vertically at a single X-value, forming a short, vertical line. Then, there\'s **one single point far away to the right**, at a much higher X-value and Y-value.\\n    *   **What it means:** This single, far-away point (often called a \\\"leverage point\\\") is almost entirely responsible for the observed correlation and the slope of the regression line. Without it, there\'s practically no relationship between X and Y among the other points. The other points barely move the line.\\n\\n### The Concrete Takeaway\\n\\nAnscombe\'s Quartet shows that:\\n\\n**You can have four completely different visual patterns and underlying relationships in your data, but they can all produce virtually the same set of basic statistical numbers.**\\n\\nTherefore, if you only look at the numbers and don\'t plot your data, you might wrongly assume a linear relationship when it\'s actually curved, driven by an outlier, or influenced by a single unusual point. You\'d be making decisions based on a misleading understanding of your data.\\n\\nDoes hearing the actual numbers and then imagining those distinct plots help bridge the gap from abstract to concrete? What do you think is the biggest surprise among the four datasets?\"}]', '2025-11-03 22:25:15'),
(93, 29, 'user', '[{\"text\":\"Explain it to a 15 year old\"}]', '2025-11-03 22:26:03'),
(94, 29, 'model', '[{\"text\":\"Okay, let\'s ditch the fancy words and explain Anscombe\'s Quartet like you\'re telling a story to a 15-year-old, maybe about their phone usage and grades.\\n\\nImagine you have four different groups of friends, and you\'re trying to see if there\'s a link between how much time they spend on their phones (`X` for screen time) and their test scores (`Y` for grades).\\n\\nFor each of these four groups, you calculate a few simple numbers:\\n*   The **average screen time** for the group.\\n*   *How much their screen times usually vary* (like, are they all glued to their phones for the same amount of time, or are some super users and some barely use them?).\\n*   The **average test score** for the group.\\n*   *How much their test scores usually vary*.\\n*   And a big one: the **\\\"connection number\\\"** (called correlation) that tells you if more screen time generally means higher or lower grades, and how strong that link seems.\\n*   You also draw a **\\\"best fit\\\" straight line** on a graph that tries to show the general trend between screen time and grades for each group.\\n\\nHere\'s the mind-blowing part, and the whole point of Anscombe\'s Quartet:\\n\\n**You can have four completely different groups of friends, where the relationship between screen time and grades is totally unique and different in each group... BUT all four groups will give you almost the EXACT SAME set of these numbers!**\\n\\nIt\'s like looking at four different people\'s social media profiles. They all have roughly the same number of followers, likes, and posts. You might think, \\\"Wow, these people are probably all pretty similar.\\\" But then you meet them in real life, and they\'re all completely different personalities with different lives!\\n\\nLet\'s \\\"meet\\\" the four groups of friends and what their data *actually looks like* if you plot it:\\n\\n1.  **Group 1: The \\\"Normal\\\" Group**\\n    *   **Numbers:** All the numbers (averages, connection number, straight line) are exactly what you\'d expect.\\n    *   **Visual (on a graph):** If you plotted their screen time vs. grades, you\'d see points scattered nicely around a straight line, like a normal trend. The numbers accurately describe what you see. No surprises!\\n\\n2.  **Group 2: The \\\"Curvy\\\" Group**\\n    *   **Numbers:** Still the *exact same numbers* as Group 1!\\n    *   **Visual (on a graph):** But if you plot this group, you\'d see a clear **curve**, maybe like a big U-shape or a rainbow. For example, maybe a little screen time (for research, studying) is good for grades, but too much screen time causes grades to drop. Even though the numbers say \\\"straight line trend,\\\" the actual picture is clearly a curve! The straight line completely *misses* the real story.\\n\\n3.  **Group 3: The \\\"One Rebel\\\" Group**\\n    *   **Numbers:** Yup, still the exact same numbers as the others!\\n    *   **Visual (on a graph):** Most of the friends in this group have a pretty clear straight-line relationship between screen time and grades. BUT, there\'s **one single friend** who is a total outlier \\u2013 maybe they have extremely high screen time *and* surprisingly good grades, or extremely low screen time *and* terrible grades. This one \\\"rebel\\\" friend is so extreme that they **pull the entire \\\"best fit\\\" straight line** way out of whack. The line looks like there\'s a trend, but it\'s only because of that one unusual person, not the whole group.\\n\\n4.  **Group 4: The \\\"Single Influencer\\\" Group**\\n    *   **Numbers:** You guessed it \\u2013 same numbers!\\n    *   **Visual (on a graph):** In this group, almost everyone has roughly the same amount of screen time, and their grades are all over the place (a messy vertical line of dots). Then, there\'s **one single friend** who has dramatically *more* screen time than anyone else, and a very specific grade. This *one friend* is so far away from everyone else that *they* are the only reason the \\\"best fit\\\" straight line has any slope at all. Without that one \\\"influencer\\\" friend, there would be no real connection between screen time and grades for anyone else in the group.\\n\\n### The Big Lesson for You:\\n\\nAnscombe\'s Quartet is a famous, powerful reminder in statistics:\\n\\n**NEVER, EVER, EVER trust just the numbers alone when you\'re looking at data.**\\n**ALWAYS, ALWAYS, ALWAYS make a picture (a graph or plot) of your data!**\\n\\nIf you only looked at the numbers for these four groups, you\'d think they all tell the same story about screen time and grades. But when you look at the actual pictures, you see four totally different and fascinating stories! What you might think is a simple trend could actually be a curve, or heavily influenced by one odd person, or even created by a single extreme data point.\\n\\nSo next time you\'re looking at any kind of data \\u2013 whether it\'s for a science project, analyzing game stats, or trying to understand trends online \\u2013 remember Anscombe\'s Quartet. **Numbers can hide the truth; visuals reveal it.**\\n\\nDoes thinking about it with \\\"screen time and grades\\\" for different groups of friends make it click a bit more? Which of these \\\"friend groups\\\" do you think is the most surprising when you compare the numbers to the actual picture?\"}]', '2025-11-03 22:26:22'),
(95, 30, 'user', '[{\"text\":\"What is chemical Pathology \"}]', '2025-11-10 07:34:37');
INSERT INTO `messages` (`id`, `conversation_id`, `role`, `content`, `created_at`) VALUES
(96, 30, 'model', '[{\"text\":\"That\'s a great question to start with! Understanding what a field is about is the first step.\\n\\nChemical Pathology is a specialized branch of medicine that uses **laboratory analysis of body fluids** (like blood, urine, or cerebrospinal fluid) to help diagnose, monitor, and manage diseases.\\n\\nLet\'s break that down a bit:\\n\\n*   **\\\"Chemical\\\"**: This refers to the analysis of various substances (chemicals) found in our body. This includes things like:\\n    *   **Sugars** (e.g., glucose for diabetes)\\n    *   **Fats** (e.g., cholesterol for heart disease risk)\\n    *   **Proteins** (e.g., albumin, enzymes like those from the liver or heart)\\n    *   **Hormones** (e.g., thyroid hormones, cortisol)\\n    *   **Electrolytes** (e.g., sodium, potassium, calcium, which are vital for many bodily functions)\\n    *   **Drugs** (to monitor therapeutic levels or detect overdose)\\n    *   **Waste products** (e.g., creatinine and urea for kidney function)\\n\\n*   **\\\"Pathology\\\"**: This is the study of disease. In this context, it means using these chemical measurements to:\\n    *   **Diagnose** a condition (e.g., high blood glucose helps diagnose diabetes).\\n    *   **Monitor** the progression of a disease (e.g., tracking a cancer marker).\\n    *   **Assess** how well a treatment is working (e.g., seeing if a medication is lowering cholesterol).\\n    *   **Screen** for potential health issues before symptoms appear.\\n\\nEssentially, Chemical Pathologists are like medical detectives who look for clues in your body\'s chemistry to understand what\'s happening inside. They interpret complex lab results to provide crucial information to other doctors, guiding patient care.\\n\\nDoes that initial explanation make sense? Can you think of any common medical tests you might have heard of that you now realize could fall under Chemical Pathology?\"}]', '2025-11-10 07:34:44'),
(97, 30, 'user', '[{\"text\":\"Yes\"}]', '2025-11-10 07:35:20'),
(98, 30, 'model', '[{\"text\":\"Great! I\'m glad that explanation clicked for you.\\n\\nTo help solidify your understanding, let\'s go back to that question:\\n\\nCan you think of any common medical tests you might have heard of that you now realize could fall under Chemical Pathology? Don\'t worry if it\'s not perfect, just give it a shot!\"}]', '2025-11-10 07:35:22'),
(99, 30, 'user', '[{\"text\":\"Electrolyte tests??\"}]', '2025-11-10 07:36:44'),
(100, 30, 'model', '[{\"text\":\"Excellent! You\'re absolutely right. **Electrolyte tests** are a perfect example of a common medical test that falls squarely within Chemical Pathology.\\n\\nWhen a doctor orders an \\\"electrolyte panel,\\\" they are looking at specific chemicals like sodium, potassium, and chloride in your blood. These tests are crucial because:\\n*   They analyze the *chemical* composition of your blood.\\n*   They help *diagnose* conditions like dehydration, kidney problems, or heart issues, and *monitor* patients receiving certain medications.\\n\\nYou\'ve successfully connected the dots between the definition of Chemical Pathology and a real-world example. That\'s fantastic!\\n\\nCan you think of *another* common medical test, perhaps one related to a different organ or body system, that might involve looking at chemicals in body fluids to understand a person\'s health?\"}]', '2025-11-10 07:36:46'),
(101, 30, 'user', '[{\"text\":\"No. Give me 5 more examples\"}]', '2025-11-10 07:40:28'),
(102, 30, 'model', '[{\"text\":\"No problem at all! It\'s great to expand your understanding with more concrete examples. Here are 5 more common medical tests that fall under Chemical Pathology, along with a brief explanation of why:\\n\\n1.  **Blood Glucose Test (e.g., for Diabetes):**\\n    *   **Why it\'s Chemical Pathology:** This test measures the level of glucose (a type of sugar, a chemical) in your blood. High levels can indicate diabetes, while monitoring helps manage the condition. It\'s all about analyzing a specific chemical to diagnose and manage disease.\\n\\n2.  **Liver Function Tests (LFTs):**\\n    *   **Why it\'s Chemical Pathology:** This is actually a panel of several tests that measure various enzymes (like ALT, AST, ALP), proteins (like albumin), and bilirubin in your blood. These chemicals are produced or processed by the liver, and their levels can indicate liver damage, inflammation, or disease.\\n\\n3.  **Kidney Function Tests (e.g., Creatinine and Urea):**\\n    *   **Why it\'s Chemical Pathology:** These tests measure the levels of waste products like creatinine and urea in your blood. Healthy kidneys filter these chemicals out of the blood into urine. Elevated levels suggest the kidneys might not be functioning effectively, making this a direct chemical analysis for disease assessment.\\n\\n4.  **Cholesterol (Lipid Panel):**\\n    *   **Why it\'s Chemical Pathology:** This test measures different types of fats (lipids), including total cholesterol, LDL (\\\"bad\\\" cholesterol), HDL (\\\"good\\\" cholesterol), and triglycerides, in your blood. These chemical levels are crucial for assessing the risk of heart disease and monitoring the effectiveness of diet or medication.\\n\\n5.  **Thyroid Hormone Tests (e.g., TSH, T3, T4):**\\n    *   **Why it\'s Chemical Pathology:** These tests measure the levels of hormones (chemical messengers) produced by your thyroid gland (like T3 and T4) and the pituitary gland (TSH, which stimulates the thyroid). Imbalances in these hormone levels can indicate an overactive or underactive thyroid, impacting metabolism and many bodily functions.\\n\\nHopefully, seeing these diverse examples helps illustrate how broad and essential Chemical Pathology is in modern medicine!\\n\\nDo you notice a common theme or purpose among all these examples we\'ve discussed, linking them back to the core definition of Chemical Pathology?\"}]', '2025-11-10 07:40:33'),
(103, 31, 'user', '[{\"text\":\"Explain the concept of conflict theory in simple terms.\"}]', '2025-11-13 20:06:39'),
(104, 31, 'model', '[{\"text\":\"That\'s a great concept to delve into! Conflict theory is a super important lens for understanding society.\\n\\nIn simple terms, imagine society not as a big, happy, cooperative team, but more like a **tug-of-war**.\\n\\nHere\'s the core idea:\\n\\n1.  **Limited Resources:** Society has limited resources \\u2013 things like money, power, status, good jobs, healthcare, education.\\n2.  **Competition:** Different groups in society are constantly **competing** for these limited resources.\\n3.  **Inequality:** This competition isn\'t fair. Some groups have more power and control over the resources (the ones winning the tug-of-war), while others have less. This creates **inequality**.\\n4.  **Conflict & Change:** Because of this inequality and the ongoing struggle for power, there\'s always an underlying (or sometimes overt) **conflict** between these groups. This conflict isn\'t necessarily violent, but it\'s a dynamic tension. This tension and struggle are actually what drive **social change**. When the less powerful push back, society shifts.\\n\\nThink of it like this: If you have a group of people, and one group has all the pie, and another group has none, the group with no pie is eventually going to challenge the group with all the pie. That challenge is the \\\"conflict,\\\" and whatever happens as a result (maybe the pie gets redistributed, or new rules are made) is the \\\"social change.\\\"\\n\\nIt suggests that stability in society is just temporary \\u2013 a snapshot of which group currently holds the most power \\u2013 and that society is always in a state of flux due to these power struggles.\\n\\nDoes that initial explanation of society as a \\\"tug-of-war\\\" and groups competing for resources resonate with your understanding so far? Or would you like to explore a specific aspect of it, like how inequality plays a role?\"}]', '2025-11-13 20:06:55'),
(105, 32, 'user', '[{\"text\":\"Context from uploaded file \'Analysis-of-Nutritional-Composition-and-Lutein-Extraction-Efficiency-from-Red-Millet.pptx\':\\n---\\nAnalysis of Nutritional Composition and Lutein Extraction Efficiency from Red Millet\\n\\nAnalysis on Red, Green and White millets (focus on red millets)\\n\\nBarbara Assibie Boaha\\n\\nIndex number: AH\\/CND\\/21\\/0093\\n\\nUniversity of Cape Coast\\n\\nIntroduction\\n\\nMillets & Context\\n\\nMillets are climate-resilient grains valued for their nutritional and health benefits. Red millet is an important traditional staple in Ghana, but research on its nutritional and lutein content is limited.\\n\\nStudy Objective\\n\\nTo evaluate the proximate composition, mineral profile, and lutein extraction efficiency of red millet obtained from Cape Coast markets.\\n\\nMaterials and Methods\\n\\n1\\n\\nSample\\n\\nRed millet (P. glaucum) purchased from Abura Market, Cape Coast.\\n\\n2\\n\\nPreparation\\n\\nGrains were washed, dried, and milled into fine powder.\\n\\n3\\n\\nExtraction\\n\\n300 g of millet were subjected to cold maceration with methanol (a 4:1 solvent-to-biomass ratio) for 120 hours. The extract was filtered, evaporated using a rotary evaporator, and dried.\\n\\nProximate Composition & Minerals (Key Nutritional Findings)\\n\\nProximate Composition (%)\\n\\nCarbohydrates\\n\\nProtein\\n\\nFat\\n\\nFiber\\n\\nMoisture\\n\\nThe analysis of red millet reveals its primary composition by percentage, highlighting carbohydrates as the most abundant component.\\n\\nKey Minerals (mg\\/100g)\\n\\nThese essential minerals are present in varying concentrations, contributing to the overall nutritional value of red millet.\\n\\nLutein Extraction and Analysis\\n\\n1\\n\\nMethanolic Extract Yield\\n\\n5.71% crude yield\\n\\n2\\n\\nTLC (Thin Layer Chromatography)\\n\\nShowed an Rf value of 0.07, which is consistent with lutein-like compounds\\n\\n3\\n\\nUV-Vis Absorbance\\n\\nAbsorbance at 343.64 nm suggested the presence of phenolics or chlorophyll derivatives rather than definitive lutein\\n\\n4\\n\\nObservation\\n\\nThe methanolic extraction gave a moderate yield of bioactive compounds. TLC suggested lutein, but UV-Vis was inconclusive, indicating the need for advanced techniques.\\n\\nConclusion\\n\\nNutritional Value\\n\\nRed millet is nutritionally valuable, providing carbohydrates, protein, fiber, and key minerals\\n\\nPublic Health Relevance\\n\\nIt is a promising source for addressing micronutrient deficiencies, especially iron deficiency anemia, due to its high iron and magnesium content\\n\\nLutein\\n\\nPreliminary evidence suggests lutein-like compounds, but further confirmation is needed\\n\\nRecommendation\\n\\nPromoting red millet can support food security, nutrition, and health in Ghana\\n\\nFuture Work & Acknowledgment\\n\\nFuture Work\\n\\n1\\n\\nApply advanced methods (HPLC-DAD\\/LC-MS) for definitive lutein identification and quantification.\\n\\n2\\n\\nInvestigate nutrient bioavailability and absorption in human diets.\\n\\n3\\n\\nDevelop value-added products and nutraceuticals from red millet.\\n\\n\\n---\\n\\nUser\'s question: explain this slides provided\"}]', '2025-11-13 20:12:22'),
(106, 32, 'model', '[{\"text\":\"Absolutely! This presentation, \\\"Analysis of Nutritional Composition and Lutein Extraction Efficiency from Red Millet,\\\" covers a research study on red millet, an important grain in Ghana.\\n\\nLet\'s break down the slides to help you understand the core message:\\n\\n---\\n\\n**1. Introduction & Context:**\\n*   **Millets & Context:** The presentation starts by explaining that millets are resilient grains, good for health, and specifically, red millet is a traditional food in Ghana. The problem is that not much research has been done on its nutritional content or on a specific compound called **lutein** in red millet.\\n*   **Study Objective:** The main goal of this research was to find out two things about red millet from Cape Coast markets:\\n    1.  Its **proximate composition** (basic nutrients like carbs, protein, fat).\\n    2.  Its **mineral profile** (which essential minerals it contains).\\n    3.  How effectively **lutein** can be extracted from it.\\n\\n**2. Materials and Methods (How they did the study):**\\n*   **Sample & Preparation:** They bought red millet, cleaned it, dried it, and ground it into a fine powder. This is standard preparation for laboratory analysis.\\n*   **Extraction:** This is a key step for analyzing compounds like lutein. They used a technique called **cold maceration** with **methanol** (a solvent).\\n    *   Think of it like steeping tea, but with millet powder and methanol.\\n    *   They let it sit for a long time (120 hours) to draw out compounds.\\n    *   Then, they filtered the liquid, evaporated the methanol (using a **rotary evaporator**) to get a concentrated \\\"extract\\\" which contains the compounds they are interested in.\\n\\n**3. Proximate Composition & Minerals (Key Nutritional Findings):**\\n*   **Proximate Composition (%):** This slide shows the basic breakdown of red millet\'s macronutrients:\\n    *   **Carbohydrates** are the most abundant.\\n    *   It also contains good amounts of **protein, fat, fiber, and moisture**.\\n    *   *In short: It\'s a good source of energy and essential dietary components.*\\n*   **Key Minerals (mg\\/100g):** The analysis also found essential minerals like iron, magnesium, zinc, etc., indicating it contributes to overall nutritional value.\\n\\n**4. Lutein Extraction and Analysis:**\\nThis section details the attempt to find and quantify lutein.\\n*   **Methanolic Extract Yield:** They successfully extracted a moderate amount (5.71%) of crude (raw) material using methanol.\\n*   **TLC (Thin Layer Chromatography):** This is a basic lab technique used to separate and identify compounds.\\n    *   The **Rf value of 0.07** suggests that there might be compounds present that behave similarly to lutein. Think of it like a preliminary \\\"matching game.\\\"\\n*   **UV-Vis Absorbance:** This is another analytical technique that measures how much light a sample absorbs at different wavelengths. Different compounds absorb light at specific wavelengths.\\n    *   The absorbance at **343.64 nm** didn\'t definitively point to lutein. Instead, it suggested the presence of other compounds like **phenolics** or **chlorophyll derivatives**.\\n    *   *This means the initial test for lutein was inconclusive\\u2014they couldn\'t definitively say \\\"yes, it\'s lutein\\\" based on this method.*\\n*   **Observation:** The summary for this section highlights that while the extraction worked and TLC hinted at lutein, the UV-Vis results were not conclusive. This indicates that more sophisticated tests are needed.\\n\\n**5. Conclusion:**\\n*   **Nutritional Value:** Red millet is confirmed to be nutritionally valuable, providing essential carbs, protein, fiber, and minerals.\\n*   **Public Health Relevance:** Due to its high iron and magnesium, it could be very important in fighting **micronutrient deficiencies** (like iron deficiency anemia) in places like Ghana.\\n*   **Lutein:** The study found *preliminary evidence* (from TLC) for lutein-like compounds, but further confirmation is required.\\n\\n**6. Recommendation & Future Work:**\\n*   **Recommendation:** The study suggests promoting red millet consumption to improve food security, nutrition, and health in Ghana.\\n*   **Future Work:** This outlines the next steps for research:\\n    1.  Use more advanced and precise techniques like **HPLC-DAD\\/LC-MS** to *definitively* identify and measure lutein.\\n    2.  Study how well the nutrients in red millet are actually absorbed and used by the human body (**bioavailability**).\\n    3.  Explore ways to create new food products or health supplements (**nutraceuticals**) from red millet.\\n\\n---\\n\\nIn essence, the presentation demonstrates that red millet is a highly nutritious grain with significant potential for improving public health, especially in Ghana. While it likely contains beneficial compounds like lutein, more advanced research is needed to confirm and quantify them.\\n\\nDoes this explanation help you understand the main points of the presentation? Is there any specific slide or term you\'d like me to elaborate on further?\"}]', '2025-11-13 20:12:35'),
(107, 33, 'user', '[{\"text\":\"Context from uploaded file \'ESS 305 - Lecture 1.pptx\':\\n---\\nESS 305: RESEARCH METHODS IN EDUCATION\\r\\n\\r\\nLECTURE ONE\\n\\nLecture Outline \\n\\nThe Nature of Educational ResearchDefinition of ResearchDefinition of Educational ResearchValue of Educational ResearchTypes of Educational Research Components of Research Report (UCC FORMAT)\\n\\nResearch! Research! Research! What is research?\\n\\nDefinition of Research\\n\\nThe term research can be used in two senses, i.e.  the layman\\u2019s sense and the scholarly sense.The layman sees research as looking up facts and writing them down.Scholars see research as more than fact-finding.To scholars, research entails the identification of a problem, collection of data, organization of data, analysis, and interpretation of the result obtained.\\n\\nDefinition of Research\\n\\nKerlinger (1873): is a systematic controlled, empirical and critical investigation of hypothetical propositions about the presumed relations among natural phenomena. This emphasizes the structured and methodical\\/systematic nature of scientific inquiry, underscoring its empirical basis and critical approach to testing hypotheses about the natural world.Creswell (2008): described research as a process of steps used to collect and analyze information to increase our understanding of a topic or issue. He highlighted that research involves three steps: posing a question, collecting data to answer the question, and presenting an answer to the question\\u200b\\u200b. Creswell\\u2019s definition emphasizes the procedural aspects of research and its goal of enhancing understanding.Kothari (2009): systematic effort to gain new knowledge; it involves the application of scientific methods to study and analyze facts or phenomena to derive new insights or confirm existing theories. The process is characterized by careful planning, rigorous analysis, and systematic inquiry, aimed at discovering \\u2026Cohen and Arieli (2011): explain that research means \\\"gathering and analyzing a body of information or data and extracting new meaning from it or developing unique solutions to problems or cases. They viewed it as an inquiry aimed at understanding, evaluating, and solving problems. They emphasized the use of systematic methods and the application\\n\\nCLASS ACTIVITY:\\r\\n\\r\\nWHAT IS THE RUNNING THEME IN THESE DEFINITIONS OF RESEARCH??\\n\\nCommon theme\\n\\nThese definitions collectively underscore the systematic, empirical, and methodological nature of research, while also highlighting its practical applications and the steps involved in the research process.\\n\\n\\r\\nDefinition of Educational Research\\r\\n\\n\\nGood (1996): a systematic process that involves the collection, analysis, and interpretation of data related to the field of education. This research aims to improve the understanding of educational processes and outcomes and to develop more effective educational practices. Munroe (2003): views educational research as an endeavor to understand and improve the educational experiences and outcomes of learners. This involves systematic inquiry into issues such as teaching methods, learning processes, and the educational environment, using various qualitative and quantitative methods to generate insights that can inform policy and practice.Mulay (2005): defines educational research as a structured investigation aimed at developing new insights into educational phenomena. The goal is to generate knowledge that enhances educational practices and policies.\\n\\nCrawford (2007): Crawford defines educational research as a systematic inquiry aimed at understanding and improving educational practices and outcomes. This involves using various methodologies to collect and analyze data to generate insights that can inform educational policy and practice.Best (2009): \\\"an activity directed towards the development of a science of behaviour in educational situations.\\\" The ultimate goal is to provide knowledge that helps educators achieve their goals using the most effective methods.Traverse (2009): describes educational research as a disciplined inquiry into educational issues, seeking to enhance the teaching and learning process through the rigorous analysis of educational practices and outcomes. This definition emphasizes the importance of using structured methodologies to derive actionable insights for improving education.\\n\\n\\r\\nDefinition of Educational Research\\r\\n\\n\\nDefinition of Educational Research\\n\\nDrawing from the definitions, we can say that educational research is:a systematic and scientific inquiry aimed at understanding, analyzing, and improving educational practices, policies, and outcomes. It involves the structured collection and analysis of data related to educational phenomena to develop knowledge that informs effective teaching strategies, enhances learning experiences, and addresses educational challenges. \\n\\nProblems that could be investigated in economics education \\n\\nEffectiveness of Online Learning in Economics Education; Teaching Methods and Student Performance, Financial Literacy levels of students in High Schools: Evaluating the effectiveness of economics education curricula in secondary education; Impact of students\\u2019 Socioeconomic Status on the learning of Economics in SHS, Use of Case Studies in Teaching Economics (Assessing the benefits of real-world examples in enhancing students\' critical thinking skills); Gender Disparities in Economics Education \\u2013 Analyzing the factors contributing to gender differences in participation and achievement in economics; Assessment Techniques in Economics Education: Exploring various assessment methods and their effectiveness in evaluating student learning outcomes; Incorporating Technology in Economics Education\\n\\nCharacteristics of Educational Research\\n\\nResearch begins with a question, an issue, or a problem in the mind of the researcher.Research requires a plan (a proposal).Research demands a clear statement of the problem.Research deals with the main problem through sub-problems.\\n\\nCharacteristics of Educational Research\\n\\nResearch seeks direction through appropriate hypotheses or questions.Research deals with fact and their meanings: A study on the impact of class size on learning outcomes collects data (facts) on student performance in different class sizes and then analyzes this data to understand how and why class size affects learning (meanings).\\u00a0Research is circular: Saying that research is cyclical means that the process of conducting research is repetitive and ongoing, rather than linear [research begins with a problem and ends with a problem]. Identification of a Problem, Literature Review: Existing literature is reviewed to understand what is already known, Hypothesis Formation, Methodology Design, Data Collection, Data Analysis, Conclusions and Implications, Publication and Peer Review, and Identification of New Problems where results lead to new questions or problems, restarting the cycle.\\n\\nValue of Educational Research\\n\\nResearch adds knowledge to an educational issueResearch in education requires addressing problems or issues in education with the view of finding solutions to them.Research adds to our knowledge by addressing the gaps in knowledge, expanding the knowledge, replicating the knowledge, and adding the voices of an individual to the knowledge.\\n\\nResearch improves practiceResearch suggests improvement for practice through scientific inquiry that recommends ways of improving on a current status.Research brings to light new ideas.Research helps practitioners to evaluate approaches that will work in any environment. E.g.: Teaching method - discussion or lecture method.\\r\\n\\n\\nValue of Educational Research\\n\\nResearch informs important policy issuesResearch guides the formulation of policy. Policy issues are broad frameworks within which things must be done. An example is the medium of instruction in the first three grades (i.e., classes 1-3).Research leads to the modification of existing policy.  \\n\\nValue of Educational Research\\n\\nResearch builds students\\u2019 research skillsThe process of research helps individuals develop conceptual, writing, organizing, and presenting skills.The skills acquired help students to evaluate or critique research works effectively.\\n\\nValue of Educational Research\\n\\nCLASS ACTIVITY:\\r\\n\\r\\nWHAT other BENEFIT(S) can oNE GET FORM THE study OF educational research??\\n\\n\\r\\nTypes of Educational Research \\r\\n\\n\\nTwo Broad TypesFundamental\\/Basic\\/Pure research.Applied research\\n\\nFundamental\\/Basic\\/Pure research\\n\\nThis research is designed to contribute to theory development and refinement of theory. It is concerned with refuting or supporting theories that explain how the social world operates. It is not concerned with practical applicability.The main purpose is to gain an understanding of an underlying process involved in, say, learning, schooling, and other educational phenomena. E.g: learning theories, such as behaviorism, constructivism, and socio-cultural theory, to understand how individuals learn and retain information.Income Inequality and Basic Needs Satisfaction among SHS students in Ghana: An Empirical Analysis. This research aims to investigate the relationship between income inequality and the satisfaction of basic human needs, as outlined in Maslow\'s hierarchy. Maslow\'s theory suggests that individuals have a hierarchy of needs, ranging from physiological needs (e.g., food, shelter) to higher-order needs such as self-esteem and self-actualization.\\n\\nApplied research\\n\\nResearch conducted to solve practical educational problems. It is conducted for the purpose of applying theory and evaluating its usefulness in solving educational problems.Some of the recent focuses of applied educational research have been grading practices, collective bargaining for school personnel, curriculum content, instructional procedures, educational technology, and assessment of achievement. The most prominent Applied Research in Education is ACTION RESEARCH.\\n\\nACTION RESEARCH\\n\\nAction research is focused on immediate applications. Its purpose is to improve school practices and at the same time, to improve those who try to improve the practices, to combine the research processes, habits of thinking, ability to work harmoniously with others, and professional spirit. The purpose of the action research is to solve classroom problems or local school problems through the application of the scientific method. Action research deals with local problems and it is conducted in a local setting and mostly carried out by teachers\\n\\nSocial impact assessment research\\n\\nThis type of research examines the broader social consequences of educational initiatives, particularly how they affect communities and stakeholders.  Eg:, an analysis of how introducing financial literacy courses in high schools influences students\\u2019 future financial decision-making and economic independence. Researchers could study the long-term effects on savings habits, investments, and entrepreneurship.\\n\\nEvaluation research\\n\\nEvaluation research assesses the effectiveness of educational programs, policies, or teaching methods to determine their impact and improve future implementation.  Eg: a study evaluating the effectiveness of digital learning platforms in teaching microeconomics principles to university students. Researchers might compare test scores before and after using the platform to measure its impact on student understanding.\\n\\nResearch & development \\n\\nR&D involves the creation and refinement of new educational tools, methodologies, or curricula based on systematic research.  Eg: the development of an interactive simulation that allows students to experiment with economic policies in a virtual market environment. Researchers would refine the tool based on student feedback and learning outcomes.\\n\\n\\r\\nComponents of Research Report \\r\\n(UCC FORMAT)\\r\\n\\n\\nTHANK YOU\\n\\n\\n---\\n\\nUser\'s question: explain the slides\"}]', '2025-11-13 20:16:46'),
(108, 33, 'model', '[{\"text\":\"That\'s a great request! You\'re looking to **understand** the core concepts presented in these lecture slides about Research Methods in Education. I\'ll walk you through each main section, explaining the key ideas.\\n\\nLet\'s break down the slides into digestible parts:\\n\\n---\\n\\n### 1. The Nature of Educational Research\\n\\nThis section introduces what research is, specifically in the context of education.\\n\\n*   **Definition of Research (Layman vs. Scholar):**\\n    *   The slides highlight that the everyday person (layman) might think research is just *finding facts and writing them down*.\\n    *   However, scholars view it as a much more rigorous process. It involves **identifying a problem, collecting and organizing data, analyzing it, and then interpreting the results.** This emphasizes a systematic, step-by-step approach.\\n    *   The slides then provide several definitions from prominent researchers (Kerlinger, Creswell, Kothari, Cohen & Arieli). The **running theme** in all these definitions is that research is a **systematic, methodological, empirical, and critical process** aimed at gaining new knowledge, increasing understanding, or solving problems through data collection and analysis.\\n\\n*   **Definition of Educational Research:**\\n    *   Building on the general definition of research, educational research specifically applies these systematic methods to the field of education.\\n    *   Researchers like Good, Munroe, Mulay, Crawford, Best, and Traverse all converge on the idea that it\'s a **systematic process** involving **data collection, analysis, and interpretation** but with the specific goal of **understanding and improving educational practices, processes, policies, and outcomes.** It\'s about making education better and more effective.\\n\\n*   **Characteristics of Educational Research:**\\n    *   The slides list several key traits:\\n        *   It always starts with a **question, issue, or problem**.\\n        *   It requires a **plan** (a research proposal).\\n        *   The **problem must be clearly stated**.\\n        *   Often, a main problem is broken down into **smaller sub-problems**.\\n        *   It seeks direction through **hypotheses or specific questions**.\\n        *   It deals with **facts and their meanings** (not just gathering facts, but interpreting what they *mean*).\\n        *   It\'s **circular (cyclical)**: Research often starts with a problem, and the findings can lead to new questions or problems, restarting the cycle of inquiry.\\n\\n*   **Problems that could be investigated in economics education:**\\n    *   The slides provide excellent examples, such as the *effectiveness of online learning*, *impact of socioeconomic status on learning*, *gender disparities*, or *incorporating technology* in economics education. These illustrate the practical, real-world issues educational research tackles.\\n\\n**To check your understanding:**\\nBased on what we\'ve covered, how would you briefly describe the main difference between how a \\\"layman\\\" and a \\\"scholar\\\" views research?\\n\\n---\\n\\n### 2. Value of Educational Research\\n\\nThis section explains *why* educational research is important and what benefits it brings.\\n\\n*   **Research Adds Knowledge:**\\n    *   It helps fill **gaps** in what we know, **expands** existing knowledge, allows us to **replicate** studies to confirm findings, and brings **diverse voices and perspectives** to educational understanding.\\n\\n*   **Research Improves Practice:**\\n    *   By finding solutions to educational problems, research provides **recommendations for improvement**. It brings to light **new ideas** and helps educators **evaluate which approaches** (e.g., teaching methods like discussion vs. lecture) work best in different environments.\\n\\n*   **Research Informs Important Policy Issues:**\\n    *   It provides evidence that **guides the formulation of new educational policies** (e.g., determining the medium of instruction for young learners).\\n    *   It can also lead to the **modification of existing policies**, ensuring they are effective and evidence-based.\\n\\n*   **Research Builds Students\' Research Skills:**\\n    *   Engaging in research helps students develop critical **conceptual, writing, organizing, and presentation skills**. These skills are valuable not just for conducting research but also for **critically evaluating** the research of others.\\n\\n**To check your understanding:**\\nCan you think of one specific way educational research might have influenced a policy or practice in a school you\'ve experienced?\\n\\n---\\n\\n### 3. Types of Educational Research\\n\\nThis section categorizes research based on its primary objective.\\n\\n*   **Two Broad Types:**\\n\\n    *   **Fundamental\\/Basic\\/Pure Research:**\\n        *   **Purpose:** Primarily focused on **developing and refining theories**. It seeks to understand underlying processes (like how learning works) without immediate concern for practical application. It aims to support or refute existing theories.\\n        *   **Example:** Studying learning theories like behaviorism or constructivism to understand how individuals acquire and retain information. Another example is researching \\\"Income Inequality and Basic Needs Satisfaction among SHS students\\\" to understand Maslow\'s hierarchy in a specific context.\\n\\n    *   **Applied Research:**\\n        *   **Purpose:** Conducted to **solve practical educational problems**. It applies existing theories to real-world situations and evaluates their usefulness in addressing specific issues.\\n        *   **Examples:** Research on grading practices, curriculum content, instructional procedures, or educational technology.\\n        *   **Action Research:** This is a prominent type of applied research, specifically focused on **immediate applications to improve school or classroom practices**. It\'s often carried out by teachers themselves to solve local, immediate problems.\\n\\n*   **Other Specific Types:**\\n\\n    *   **Social Impact Assessment Research:**\\n        *   **Purpose:** Examines the **broader social consequences** of educational initiatives on communities and stakeholders.\\n        *   **Example:** Analyzing how financial literacy courses in high schools influence students\' long-term financial decisions (savings, investments).\\n\\n    *   **Evaluation Research:**\\n        *   **Purpose:** **Assesses the effectiveness** of educational programs, policies, or teaching methods to determine their impact and identify areas for improvement.\\n        *   **Example:** Comparing test scores before and after using a new digital learning platform to see if it improved student understanding of microeconomics.\\n\\n    *   **Research & Development (R&D):**\\n        *   **Purpose:** Involves the **creation and refinement of new educational tools, methodologies, or curricula** based on systematic research.\\n        *   **Example:** Developing an interactive simulation for economics students and refining it based on their feedback and learning outcomes.\\n\\n**To check your understanding:**\\nIf a teacher wants to find out if a new teaching method improves their students\' grades in *their specific classroom*, which type of research would be most directly relevant and why?\\n\\n---\\n\\n### 4. Components of Research Report (UCC FORMAT)\\n\\nThis is a heading in the slides but doesn\'t have detailed content provided. It simply indicates that in this course (ESS 305 at UCC), you will learn about the standard structure and required sections of a formal research report. Typically, this would cover things like the Introduction, Literature Review, Methodology, Results, Discussion, and Conclusion.\\n\\n---\\n\\nI hope this explanation helps you understand the key concepts presented in the slides! Do you have any specific part you\'d like me to elaborate on further, or perhaps a question that came to mind while reading?\"}]', '2025-11-13 20:16:59'),
(115, 37, 'user', '[{\"text\":\"explain chain rule\"}]', '2025-11-13 22:12:12'),
(116, 37, 'model', '[{\"text\":\"That\'s a great question to ask, as the chain rule is fundamental in calculus for understanding how functions change!\\n\\nAt its core, the **chain rule** helps us find the derivative of a **composite function**. Think of a composite function as a \\\"function within a function,\\\" or like a set of Russian nesting dolls.\\n\\n### Intuitive Idea: Rate of Change of a Rate of Change\\n\\nImagine you\'re driving, and your speed depends on how hard you press the gas pedal. But how hard you press the gas pedal might also depend on how you\'re feeling that day.\\n\\n*   **Function 1 (Outer):** Your speed depends on the pedal position.\\n*   **Function 2 (Inner):** The pedal position depends on your mood.\\n\\nIf you want to know how your speed changes with your mood, you need to consider *both* rates of change:\\n1.  How much your speed changes for a given change in pedal position.\\n2.  How much the pedal position changes for a given change in your mood.\\n\\nThe chain rule combines these to give you the overall rate of change.\\n\\n### Formal Definition\\n\\nIf you have a composite function $h(x) = f(g(x))$, where $f$ is the \\\"outer\\\" function and $g$ is the \\\"inner\\\" function, then its derivative $h\'(x)$ is given by:\\n\\n$$ \\\\frac{d}{dx}[f(g(x))] = f\'(g(x)) \\\\cdot g\'(x) $$\\n\\nLet\'s break that down:\\n\\n*   $f\'(g(x))$: This is the derivative of the **outer function**, evaluated at the **inner function**. It means you take the derivative of $f$ *as if* $g(x)$ were a single variable, and then substitute $g(x)$ back in.\\n*   $g\'(x)$: This is the derivative of the **inner function**.\\n\\nEssentially, you differentiate the \\\"outside\\\" function first, then multiply by the derivative of the \\\"inside\\\" function.\\n\\nAnother way to write it, often using substitution:\\n\\nIf $y = f(u)$ and $u = g(x)$, then\\n$$ \\\\frac{dy}{dx} = \\\\frac{dy}{du} \\\\cdot \\\\frac{du}{dx} $$\\nHere, $\\\\frac{dy}{du}$ is the derivative of the outer function $f$ with respect to its input $u$, and $\\\\frac{du}{dx}$ is the derivative of the inner function $g$ with respect to $x$.\\n\\n### Example Time!\\n\\nLet\'s find the derivative of $y = (x^2 + 3x)^5$.\\n\\n1.  **Identify the outer and inner functions:**\\n    *   **Outer function** ($f(u)$): Something raised to the power of 5. Let $u = x^2 + 3x$. So, $f(u) = u^5$.\\n    *   **Inner function** ($g(x)$): The expression inside the parentheses. So, $g(x) = x^2 + 3x$.\\n\\n2.  **Find the derivative of the outer function ($f\'(u)$):**\\n    *   If $f(u) = u^5$, then $f\'(u) = 5u^4$.\\n\\n3.  **Find the derivative of the inner function ($g\'(x)$):**\\n    *   If $g(x) = x^2 + 3x$, then $g\'(x) = 2x + 3$.\\n\\n4.  **Apply the chain rule formula:** $f\'(g(x)) \\\\cdot g\'(x)$\\n    *   Substitute $g(x)$ back into $f\'(u)$: $5(x^2 + 3x)^4$.\\n    *   Multiply by $g\'(x)$: $(2x + 3)$.\\n\\nSo, the derivative is:\\n$$ \\\\frac{dy}{dx} = 5(x^2 + 3x)^4 \\\\cdot (2x + 3) $$\\n\\nDoes that explanation and example help you start to \\\"understand\\\" the chain rule? Would you like to try another example, or perhaps apply it to a slightly different type of function?\"}]', '2025-11-13 22:12:22'),
(117, 38, 'user', '[{\"text\":\"Solve 2x+3=7 step by step\"}]', '2025-11-13 22:17:39'),
(118, 38, 'model', '[{\"text\":\"That\'s a great problem to work through! Solving equations is a fundamental skill in mathematics, and understanding *why* each step works is key.\\n\\nOur goal when solving an equation like $2x + 3 = 7$ is to isolate the variable, $x$, on one side of the equation. Think of the equation as a balanced scale: whatever you do to one side, you must do to the other to keep it balanced.\\n\\nLet\'s break it down step-by-step:\\n\\n### Equation: $2x + 3 = 7$\\n\\n**Step 1: Isolate the term with \'x\'**\\n\\n*   Currently, $3$ is being added to $2x$. To get rid of the $+3$, we need to perform the opposite (inverse) operation, which is subtraction.\\n*   We\'ll subtract $3$ from **both sides** of the equation to keep it balanced:\\n    $$2x + 3 - 3 = 7 - 3$$\\n*   On the left side, $+3$ and $-3$ cancel each other out, leaving $2x$.\\n*   On the right side, $7 - 3$ equals $4$.\\n*   This simplifies the equation to:\\n    $$2x = 4$$\\n    *Why we do this:* We\'re peeling away the numbers around $x$ layer by layer. We start with the terms added or subtracted, then move to terms multiplied or divided.\\n\\n**Step 2: Isolate \'x\'**\\n\\n*   Now we have $2x = 4$. This means \\\"$2$ multiplied by $x$ equals $4$.\\\"\\n*   To get $x$ by itself, we need to perform the inverse operation of multiplication, which is division.\\n*   We\'ll divide **both sides** of the equation by $2$:\\n    $$\\\\frac{2x}{2} = \\\\frac{4}{2}$$\\n*   On the left side, $\\\\frac{2x}{2}$ simplifies to $x$.\\n*   On the right side, $\\\\frac{4}{2}$ equals $2$.\\n*   This leaves us with our solution:\\n    $$x = 2$$\\n    *Why we do this:* We\'re undoing the multiplication to find the value of $x$.\\n\\n**Step 3: Check your answer (Optional, but highly recommended!)**\\n\\n*   To make sure our solution is correct, we can substitute $x=2$ back into the original equation:\\n    $$2x + 3 = 7$$\\n    $$2(2) + 3 = 7$$\\n    $$4 + 3 = 7$$\\n    $$7 = 7$$\\n*   Since both sides are equal, our solution $x=2$ is correct!\\n\\n**In summary:**\\n\\n1.  **Undo addition\\/subtraction:** Subtract 3 from both sides.\\n2.  **Undo multiplication\\/division:** Divide by 2 on both sides.\\n\\nDoes that explanation of *why* we do each step make sense?\\n\\nTo check your understanding, could you try to solve this similar equation and tell me your steps?\\n$$3y - 5 = 10$$\"}]', '2025-11-13 22:17:50'),
(119, 38, 'user', '[{\"text\":\"I first move 5 over the equal sign to the right. Since it\'s negative, it becomes positive 5. 10 + 5 becomes 15. the equation is now 3y = 15. 3 divides 15, making y equal to 5\"}]', '2025-11-13 22:21:45'),
(120, 38, 'model', '[{\"text\":\"Fantastic! You\'ve got it exactly right!\\n\\nYour steps are perfect:\\n\\n1.  **You correctly identified that to undo the \\\"$-5$\\\", you add $5$ to both sides.** This is what\'s happening when you say \\\"move 5 over the equal sign and it becomes positive.\\\" You\'re essentially doing this to keep the scale balanced:\\n    $$3y - 5 + 5 = 10 + 5$$\\n    $$3y = 15$$\\n2.  **Then, you correctly saw that to undo the \\\"multiply by 3\\\", you divide by 3 on both sides.**\\n    $$\\\\frac{3y}{3} = \\\\frac{15}{3}$$\\n    $$y = 5$$\\n\\nAnd your final answer, $y=5$, is absolutely correct!\\n\\nYou\'re clearly grasping the concept of inverse operations to isolate the variable. That\'s a strong **understanding** of how to solve these types of equations.\\n\\nWould you like to try one that\'s a little bit different, perhaps involving a negative number in front of the variable, or a fraction? Or would you prefer to explore *why* these inverse operations work to keep the equation balanced?\"}]', '2025-11-13 22:21:50'),
(121, 39, 'user', '[{\"text\":\"Solve 2x+3=7 step by step\"}]', '2025-11-13 22:26:44'),
(122, 39, 'model', '[{\"text\":\"That\'s a great equation to practice with! Let\'s break down how to solve $2x+3=7$ step by step, focusing on *why* we do each step so you can apply it to other problems.\\n\\nThe main goal when solving an equation like this is to **isolate the variable $x$** \\u2013 that means getting $x$ all by itself on one side of the equals sign.\\n\\nHere\\u2019s how we do it:\\n\\n### Step 1: Undo Addition or Subtraction\\n\\nFirst, we want to get rid of any numbers that are being added to or subtracted from the term with $x$. In our equation, we have a `+3`.\\n\\n*   **Equation:** $2x + 3 = 7$\\n*   **Why?** To get rid of the `+3` on the left side, we need to perform the opposite (inverse) operation, which is subtraction. To keep the equation balanced (meaning both sides are still equal), whatever we do to one side, we *must* do to the other side.\\n*   **Action:** Subtract 3 from both sides of the equation.\\n\\n    $$ 2x + 3 \\\\mathbf{- 3} = 7 \\\\mathbf{- 3} $$\\n\\n*   **Result:** The `+3` and `-3` on the left cancel each other out, and $7 - 3$ simplifies on the right:\\n\\n    $$ 2x = 4 $$\\n\\n### Step 2: Undo Multiplication or Division\\n\\nNow that we have the term with $x$ by itself (`2x`), we need to get rid of the number that is multiplying $x$. In our equation, $2x$ means $2 \\\\times x$.\\n\\n*   **Equation:** $2x = 4$\\n*   **Why?** To get `x` by itself, we need to perform the opposite (inverse) operation of multiplication, which is division. Again, to keep the equation balanced, we divide both sides by the same number.\\n*   **Action:** Divide both sides of the equation by 2.\\n\\n    $$ \\\\frac{2x}{\\\\mathbf{2}} = \\\\frac{4}{\\\\mathbf{2}} $$\\n\\n*   **Result:** The `2` in the numerator and denominator on the left cancel out, leaving just `x`. On the right, $4 \\\\div 2$ simplifies:\\n\\n    $$ x = 2 $$\\n\\n### Step 3: Check Your Answer (Optional, but highly recommended!)\\n\\nTo make sure our solution is correct, we can substitute the value we found for $x$ back into the *original* equation.\\n\\n*   **Original Equation:** $2x + 3 = 7$\\n*   **Substitute $x=2$:** $2(\\\\mathbf{2}) + 3 = 7$\\n*   **Simplify:** $4 + 3 = 7$\\n*   **Verify:** $7 = 7$\\n\\nSince both sides are equal, our solution $x=2$ is correct!\\n\\n---\\n\\n**To check your understanding, could you explain in your own words why we subtract 3 from both sides in the first step?**\"}]', '2025-11-13 22:26:56'),
(123, 40, 'user', '[{\"text\":\"Solve 2x+3=7 step by step\"}]', '2025-11-14 00:20:40'),
(124, 40, 'model', '[{\"text\":\"Great choice! Solving equations like $2x + 3 = 7$ is a fundamental skill in algebra, and understanding each step is key. Our goal is to figure out what value of $x$ makes the equation true.\\n\\nLet\'s break it down step-by-step:\\n\\n$$2x + 3 = 7$$\\n\\n**Step 1: Isolate the term with $x$.**\\nRight now, the $2x$ term has a $+3$ next to it. To get rid of this $+3$ and start isolating $2x$, we need to perform the opposite operation. The opposite of adding 3 is subtracting 3.\\n\\nCrucially, whatever you do to one side of the equation, you **must** do to the other side to keep the equation balanced. Think of an equation like a balanced scale: if you take weight off one side, you have to take the same weight off the other side to keep it level.\\n\\nSo, let\'s subtract 3 from both sides:\\n\\n$$2x + 3 - 3 = 7 - 3$$\\n\\nWhat happens to the $+3 - 3$ on the left side, and what does the right side become after subtracting? Take a moment to think about it!\"}]', '2025-11-14 00:20:48'),
(125, 40, 'user', '[{\"text\":\"On the left, it becomes 0 and 4 on the right side\"}]', '2025-11-14 00:21:48'),
(126, 40, 'model', '[{\"text\":\"Exactly! You\'ve got it.\\n\\nSo, after subtracting 3 from both sides, the equation becomes:\\n\\n$$2x = 4$$\\n\\nNow, our goal is to get $x$ completely by itself. What operation is currently happening between the $2$ and the $x$ (i.e., $2x$)? And what would be the opposite operation to undo it and leave just $x$?\\n\\nRemember, whatever you do to one side, you must do to the other!\"}]', '2025-11-14 00:21:51'),
(127, 40, 'user', '[{\"text\":\"Divide both sides by 2\"}]', '2025-11-14 00:22:10'),
(128, 40, 'model', '[{\"text\":\"Perfect! That\'s precisely the right move.\\n\\nSince $2x$ means \\\"2 multiplied by $x$\\\", the opposite operation to undo that multiplication and isolate $x$ is to divide by 2. And, as you correctly noted, we must do it to both sides of the equation to maintain balance:\\n\\n$$\\\\frac{2x}{2} = \\\\frac{4}{2}$$\\n\\nNow, perform that division on both sides. What does $x$ equal?\"}]', '2025-11-14 00:22:12'),
(129, 40, 'user', '[{\"text\":\"2\"}]', '2025-11-14 00:22:23'),
(130, 40, 'model', '[{\"text\":\"Excellent! You\'ve correctly solved it.\\n\\nWhen we divide both sides by 2:\\n\\n$$\\\\frac{2x}{2} = \\\\frac{4}{2}$$\\n\\nThe $2$\'s on the left cancel out, leaving just $x$, and $4 \\\\div 2$ equals $2$. So, you get:\\n\\n$$x = 2$$\\n\\nYou\'ve successfully solved the equation $2x + 3 = 7$ step-by-step!\\n\\nTo make sure we truly understand what this means, how could you **check** your answer to verify that $x=2$ is indeed the correct solution for the original equation? What would you do?\"}]', '2025-11-14 00:22:26'),
(131, 40, 'user', '[{\"text\":\"assign 2 to x. it becomes 2(2)+3 = 7. on both sides, they become 7\"}]', '2025-11-14 00:23:52');
INSERT INTO `messages` (`id`, `conversation_id`, `role`, `content`, `created_at`) VALUES
(132, 40, 'model', '[{\"text\":\"That\'s absolutely spot on!\\n\\nYou would substitute the value you found for $x$ back into the **original equation**:\\n\\n$$2x + 3 = 7$$\\n\\nSubstituting $x=2$:\\n\\n$$2(2) + 3 = 7$$\\n$$4 + 3 = 7$$\\n$$7 = 7$$\\n\\nSince both sides of the equation are equal, you know that $x=2$ is indeed the correct solution. This is a fantastic habit to get into when solving equations, as it lets you confirm your work!\\n\\nYou\'ve demonstrated a strong understanding of how to solve a two-step linear equation and how to verify your solution.\\n\\nWould you like to try another similar equation, perhaps one that involves a negative number, or would you like to explore *why* we perform inverse operations to solve equations?\"}]', '2025-11-14 00:23:56'),
(133, 41, 'user', '[{\"text\":\"take me through pythagoras theorem\"}]', '2025-11-14 00:26:04'),
(134, 41, 'model', '[{\"text\":\"Great! The Pythagorean theorem is a fundamental concept in geometry, and I\'d be happy to take you through it. Our goal here is for you to **understand** what it is, when to use it, and why it works.\\n\\nTo start, have you encountered the concept of a right-angled triangle before? Or are you completely new to the theorem? Knowing where you\'re starting from will help me tailor the explanation perfectly!\\n\\nNo worries if you haven\'t, we can start from the very beginning. Just let me know!\"}]', '2025-11-14 00:26:10'),
(135, 41, 'user', '[{\"text\":\"I have no idea about it\"}]', '2025-11-14 00:26:26'),
(136, 41, 'model', '[{\"text\":\"No problem at all! That\'s a perfect place to start. Let\'s build this understanding from the ground up.\\n\\nThe Pythagorean theorem is all about a very specific type of triangle: the **right-angled triangle**.\\n\\n### Step 1: What is a Right-Angled Triangle?\\n\\nImagine a corner of a square room, or the corner of a book. That perfect, crisp corner forms an angle of exactly 90 degrees. This is called a **right angle**.\\n\\nA **right-angled triangle** is simply a triangle that contains one of these 90-degree angles.\\n\\n<img src=\\\"https:\\/\\/upload.wikimedia.org\\/wikipedia\\/commons\\/thumb\\/1\\/1d\\/Right_triangle_with_a_and_b_legs_and_c_hypotenuse.svg\\/500px-Right_triangle_with_a_and_b_legs_and_c_hypotenuse.svg.png\\\" width=\\\"300\\\">\\n\\nIn the image above, the square symbol in one corner indicates the 90-degree angle.\\n\\n### Step 2: The Special Sides of a Right-Angled Triangle\\n\\nIn a right-angled triangle, the sides have special names:\\n\\n1.  **Legs (or Cathetus)**: These are the two sides that form the right angle. In the picture, they are labeled \'a\' and \'b\'.\\n2.  **Hypotenuse**: This is the longest side of the right-angled triangle, and it\'s *always* opposite the right angle. In the picture, it\'s labeled \'c\'.\\n\\n### Step 3: Introducing the Pythagorean Theorem\\n\\nNow for the theorem itself! The Pythagorean theorem states a very simple but powerful relationship between the lengths of the sides of **any** right-angled triangle.\\n\\nIt says:\\n\\n**The square of the length of the hypotenuse (c) is equal to the sum of the squares of the lengths of the other two sides (a and b).**\\n\\nIn mathematical terms, this is written as:\\n\\n$$a^2 + b^2 = c^2$$\\n\\nWhere:\\n*   `a` and `b` are the lengths of the legs\\n*   `c` is the length of the hypotenuse\\n\\n### Step 4: Let\'s See It in Action (A Simple Example)\\n\\nImagine you have a right-angled triangle where:\\n*   One leg (a) is 3 units long.\\n*   The other leg (b) is 4 units long.\\n\\nCan we find the length of the hypotenuse (c)?\\n\\nUsing the formula:\\n$a^2 + b^2 = c^2$\\n$3^2 + 4^2 = c^2$\\n$9 + 16 = c^2$\\n$25 = c^2$\\n\\nTo find `c`, we take the square root of both sides:\\n$c = \\\\sqrt{25}$\\n$c = 5$\\n\\nSo, the hypotenuse is 5 units long!\\n\\n---\\n\\nHow does that initial explanation sit with you? Does the idea of a right-angled triangle and its special sides, along with the formula $a^2 + b^2 = c^2$, make sense so far?\"}]', '2025-11-14 00:26:31'),
(141, 44, 'user', '[{\"text\":\"explain angular accelaration\"}]', '2025-11-14 14:04:56'),
(142, 44, 'model', '[{\"text\":\"That\'s a great question! Understanding angular acceleration is key to understanding how things spin and rotate.\\n\\nTo get started, let\'s think about something you might be more familiar with: **linear acceleration**.\\n\\n1.  **What does it mean for an object to have linear acceleration?**\\n2.  **Can you think of an everyday example of something with linear acceleration?**\"}]', '2025-11-14 14:05:04'),
(143, 44, 'user', '[{\"text\":\"A car moving in a straight line\"}]', '2025-11-14 14:05:40'),
(144, 44, 'model', '[{\"text\":\"Excellent! A car moving in a straight line can definitely have linear acceleration.\\n\\nNow, let\'s take that a step further. If a car has linear acceleration, what does that tell us about its **speed** or **velocity**? In other words, how would you *define* linear acceleration in the context of your car example?\"}]', '2025-11-14 14:05:49'),
(145, 44, 'user', '[{\"text\":\"It\'s moving at a constant velocity per second\"}]', '2025-11-14 14:06:25'),
(146, 44, 'model', '[{\"text\":\"You\'re very close! That\'s a great thought about \\\"per second.\\\"\\n\\nIf a car is moving at a **constant velocity**, what would its acceleration be? Think about if the car\'s speed or direction is changing.\\n\\nWhat do you think needs to change about the car\'s motion for it to *have* linear acceleration?\"}]', '2025-11-14 14:06:37'),
(147, 44, 'user', '[{\"text\":\"Its velocity\"}]', '2025-11-14 14:07:28'),
(148, 44, 'model', '[{\"text\":\"Exactly! For an object to have **linear acceleration**, its **velocity must be changing**.\\n\\nSo, we can define linear acceleration as the **rate at which an object\'s velocity changes over time**. If the car speeds up, slows down, or changes direction, it\'s accelerating.\\n\\nNow, let\'s apply this idea to things that spin or rotate. Instead of moving in a straight line, imagine an object like a spinning top, a Ferris wheel, or the hands of a clock.\\n\\nWhen we talk about spinning, we use the term **angular velocity**. Just as linear velocity tells us how fast an object is moving in a line, angular velocity tells us how fast an object is **rotating** or **spinning**. It\'s often measured in radians per second.\\n\\nGiven what we\'ve just discussed about linear acceleration and how it relates to a *change* in linear velocity, how would you define **angular acceleration** in your own words, thinking about an object that is rotating?\"}]', '2025-11-14 14:07:45'),
(149, 44, 'user', '[{\"text\":\"it is the rate of change of spinning or rotation of an object\"}]', '2025-11-14 14:09:01'),
(150, 44, 'model', '[{\"text\":\"You\'ve got it perfectly! That\'s a fantastic way to put it.\\n\\nMore formally, **angular acceleration** is indeed the **rate at which an object\'s angular velocity changes over time.**\\n\\nJust like linear acceleration tells us how quickly an object\'s linear velocity (speed in a straight line) is changing, angular acceleration tells us how quickly an object\'s **angular velocity** (its rate of spinning or rotating) is changing.\\n\\n*   We often denote angular acceleration with the Greek letter **alpha** ($\\\\alpha$).\\n*   Its standard units are **radians per second squared** ($\\\\text{rad\\/s}^2$).\\n\\nLet\'s use an example to solidify this:\\n\\nImagine a ceiling fan.\\n*   When you first turn it on, it starts from rest and gradually spins faster and faster. During this time, its **angular velocity is increasing**, meaning it has a positive **angular acceleration**.\\n*   Once it reaches its desired speed and stays there, its angular velocity is constant. At this point, its angular acceleration would be **zero**.\\n*   If you then turn the fan off, it will slow down and eventually stop. While it\'s slowing down, its **angular velocity is decreasing**, meaning it has a negative **angular acceleration** (sometimes called angular deceleration).\\n\\nDoes that make sense? Can you think of another example of something that experiences angular acceleration?\"}]', '2025-11-14 14:09:07'),
(151, 45, 'user', '[{\"text\":\"Explain Anscombe\\u2019s quartet\"}]', '2025-11-16 00:06:44'),
(152, 45, 'model', '[{\"text\":\"That\'s an excellent question! Anscombe\'s Quartet is a famous and incredibly insightful demonstration in statistics that helps us understand the importance of visualizing data.\\n\\nAt its core, **Anscombe\'s Quartet is a set of four distinct datasets that have nearly identical basic statistical properties, yet look dramatically different when plotted on a graph.**\\n\\nHere\'s a breakdown of what that means and why it\'s so important:\\n\\n### The Problem it Addresses: Summary Statistics Can Be Misleading\\n\\nWhen we analyze data, we often calculate summary statistics like:\\n*   **Mean**: The average value.\\n*   **Variance\\/Standard Deviation**: How spread out the data is.\\n*   **Correlation Coefficient**: How strongly two variables (like X and Y) are linearly related.\\n*   **Linear Regression Line**: A line that best describes the linear relationship between X and Y.\\n\\nAnscombe\'s Quartet shows us that relying solely on these numbers can be very deceiving.\\n\\n### The Four Datasets\\n\\nEach of the four datasets in the quartet consists of eleven (x, y) points. For all four datasets, these statistics are almost identical:\\n\\n*   **Mean of x**: 9.0\\n*   **Variance of x**: 11.0\\n*   **Mean of y**: 7.5\\n*   **Variance of y**: 4.12\\n*   **Correlation between x and y**: 0.816\\n*   **Linear Regression Equation**: $y = 0.5x + 3$\\n\\nIf you only looked at these numbers, you would conclude that all four datasets describe essentially the same relationship between X and Y. However, when you plot them, their true nature is revealed:\\n\\n1.  **Dataset I (Linear)**:\\n    *   **Appearance**: This dataset shows a clear, positive **linear relationship** between X and Y, with some random scattering around the regression line. This is the kind of data where the summary statistics (especially the linear correlation and regression) are genuinely descriptive.\\n    *   **Takeaway**: This is often what we *assume* data looks like when we calculate these statistics.\\n\\n2.  **Dataset II (Curvilinear)**:\\n    *   **Appearance**: This dataset shows a strong **curvilinear (non-linear) relationship**, specifically a parabolic shape. The Y values first increase and then decrease as X increases.\\n    *   **Takeaway**: While the linear correlation is still high (0.816), it completely fails to capture the actual shape of the relationship. A linear regression line through this data would be misleading, as the relationship isn\'t linear at all.\\n\\n3.  **Dataset III (Outlier Influenced)**:\\n    *   **Appearance**: This dataset shows a perfect **linear relationship** for ten of the points, but one single **outlier** significantly pulls the regression line (and boosts the correlation coefficient) towards it.\\n    *   **Takeaway**: The \\\"linear\\\" relationship described by the statistics is almost entirely due to that one outlier. Without it, the data would suggest a different, weaker, or even non-existent linear trend. This highlights how sensitive statistics can be to unusual points.\\n\\n4.  **Dataset IV (Single Point Dominance)**:\\n    *   **Appearance**: This dataset has almost all its X values identical (e.g., at X=8), except for one outlier with a very different X value (e.g., at X=19). This single outlier **determines almost the entire linear regression line and correlation**. Without it, there\'s no meaningful linear relationship between X and Y to speak of.\\n    *   **Takeaway**: Similar to Dataset III, a single point here dictates the statistics, but in an even more extreme way. The data itself shows no intrinsic linear relationship among the majority of points.\\n\\n### The Core Lesson: Always Visualize Your Data!\\n\\nThe profound lesson of Anscombe\'s Quartet is that **summary statistics alone are insufficient for understanding a dataset.** They can hide crucial patterns, outliers, and the true nature of relationships between variables.\\n\\nBefore drawing any conclusions or making decisions based on data, you should always **plot your data** (e.g., using scatter plots) to visually inspect it. This allows you to:\\n*   Identify the actual shape of relationships (linear, curved, etc.).\\n*   Detect outliers or influential points.\\n*   Avoid making incorrect assumptions about your data.\\n\\nDoes seeing how different these datasets can look, despite having the same numbers, help you understand why visualization is so critical in data analysis?\"}]', '2025-11-16 00:06:55'),
(153, 46, 'user', '[{\"text\":\"Explain the concept of circle theorem in simple terms.\"}]', '2025-11-16 12:04:59'),
(154, 46, 'model', '[{\"text\":\"That\'s a great question! Circle theorems can seem a bit intimidating at first because there are a few of them, but they are essentially just **rules or properties that are always true for circles and the lines and angles within them.**\\n\\nThink of a circle as having its own set of \\\"laws\\\" that it always follows. These laws help us figure out missing angles or lengths in diagrams that involve circles, without having to measure anything.\\n\\nLet\'s break down the core idea with an example, using one of the most fundamental circle theorems:\\n\\n### The \\\"Angle at the Center\\\" Theorem\\n\\nImagine you have a slice of pizza.\\n\\n1.  **The \\\"Center Angle\\\":** If you look at the angle formed by the crust where your hands meet at the *center* of the pizza, that\'s one angle. Let\'s call the points on the crust A and B, and the center O. So we\'re looking at the angle $\\\\angle AOB$.\\n\\n2.  **The \\\"Circumference Angle\\\":** Now, imagine you\'re a tiny ant standing anywhere else on the *edge* (circumference) of the pizza, not between A and B, but on the *other* side. If you looked back at the same piece of crust (arc AB), you would see a different angle. Let\'s say the ant is at point C on the circumference, looking at arc AB. This is angle $\\\\angle ACB$.\\n\\n**The rule (theorem) says:**\\nThe angle formed at the **center** of the circle ($\\\\angle AOB$) by an arc is **double** the angle formed by the *same arc* at **any point on the circumference** ($\\\\angle ACB$).\\n\\nIn mathematical terms:\\n$$ \\\\angle AOB = 2 \\\\times \\\\angle ACB $$\\n\\nThis is always true, no matter how big the circle is, or where point C is on the circumference (as long as it\'s on the \\\"major arc\\\" for the \\\"minor arc\\\" AB).\\n\\nSo, if you knew the angle at the circumference was $30^\\\\circ$, you\'d immediately know the angle at the center is $60^\\\\circ$!\\n\\nDoes that initial explanation of what a circle theorem is, and that first example, make sense? We can dive into more examples or clarify anything you\'d like!\"}]', '2025-11-16 12:05:07'),
(156, 48, 'user', '[{\"text\":\"As a university student, teach me about algorithms\"}]', '2025-11-19 01:53:05'),
(157, 48, 'model', '[{\"text\":\"That\'s a fantastic topic for a university student to dive into! Algorithms are fundamental to so many fields, from computer science and mathematics to economics and even everyday life.\\n\\nLet\'s start with the basics to ensure we build a solid understanding.\\n\\nAt its core, an **algorithm** is simply a **step-by-step procedure or a set of well-defined instructions to solve a specific problem or accomplish a task.**\\n\\nThink of it like a recipe for cooking:\\n\\n1.  **Input:** You start with ingredients (e.g., flour, eggs, sugar).\\n2.  **Steps:** You follow specific instructions in a particular order (e.g., \\\"Mix flour and sugar,\\\" \\\"Add eggs,\\\" \\\"Bake at 350\\u00b0F for 30 minutes\\\").\\n3.  **Output:** You get a desired result (e.g., a cake).\\n\\nIn computer science, algorithms are essentially the blueprints for how software works. They tell a computer exactly what to do, step by step, to process data or achieve a goal.\\n\\nHere are some key characteristics that define a good algorithm:\\n\\n*   **Finite:** It must terminate after a finite number of steps. It can\'t run forever.\\n*   **Well-defined:** Each step must be precise and unambiguous. There should be no room for interpretation.\\n*   **Input:** It takes zero or more inputs (the data it will operate on).\\n*   **Output:** It produces one or more outputs (the result of the operation).\\n*   **Effective:** Each step must be simple enough that it can, in principle, be carried out exactly and in a finite amount of time.\\n\\nFor example, consider an algorithm to find the largest number in a list of positive numbers:\\n\\n1.  Start by assuming the first number in the list is the largest.\\n2.  Go through the rest of the numbers one by one.\\n3.  If you find a number that is larger than your current \'largest\', update your \'largest\' to this new number.\\n4.  Once you\'ve checked all numbers, the number you currently have stored as \'largest\' is the final output.\\n\\nThis is a simple algorithm with clear steps, input (the list of numbers), and output (the largest number).\\n\\nTo check your understanding, can you think of another everyday example of an algorithm you follow regularly, perhaps outside of cooking? What are its inputs, steps, and expected output?\"}]', '2025-11-19 01:53:14'),
(158, 48, 'user', '[{\"text\":\"Going to the library. I walk to the junction. Then pick a cab to Science. Then walk 1km to Sam Jonah Library\"}]', '2025-11-19 01:54:57'),
(159, 48, 'model', '[{\"text\":\"That\'s an excellent example! \\\"Going to the library\\\" definitely fits the definition of an algorithm.\\n\\nLet\'s break down your example using the characteristics we discussed:\\n\\n*   **Problem:** Get to the Sam Jonah Library.\\n*   **Input:** Your current location (where you start walking to the junction from).\\n*   **Steps:**\\n    1.  Walk to the junction.\\n    2.  Pick a cab to Science.\\n    3.  Walk 1km to Sam Jonah Library.\\n*   **Output:** You are at the Sam Jonah Library.\\n\\nAnd does it meet the other characteristics?\\n\\n*   **Finite?** Yes, you expect to arrive at the library within a reasonable time, not walk forever.\\n*   **Well-defined?** Mostly! \\\"Walk to the junction\\\" is pretty clear. \\\"Pick a cab to Science\\\" is also fairly specific. \\\"Walk 1km to Sam Jonah Library\\\" is also precise.\\n\\nYou\'ve successfully mapped an everyday task to the definition of an algorithm!\\n\\nNow, let\'s push your understanding a bit further. In the context of computer algorithms, we often need instructions to be incredibly precise, leaving no room for ambiguity.\\n\\nConsider your step: \\\"Pick a cab to Science.\\\"\\n\\nIf you were trying to give these instructions to a robot or program a self-driving car, what kind of *more detailed instructions* might be needed for \\\"pick a cab\\\"? For example, what if there are no cabs available, or multiple cabs? What additional steps or conditions might need to be defined to make that instruction truly unambiguous for a machine?\"}]', '2025-11-19 01:55:03'),
(160, 49, 'user', '[{\"text\":\"Context from uploaded file \'Analysis-of-Nutritional-Composition-and-Lutein-Extraction-Efficiency-from-Red-Millet (1).pptx\':\\n---\\nAnalysis of Nutritional Composition and Lutein Extraction Efficiency from Red Millet\\n\\nAnalysis on Red, Green and White millets (focus on red millets)\\n\\nBarbara Assibie Boaha\\n\\nIndex number: AH\\/CND\\/21\\/0093\\n\\nUniversity of Cape Coast\\n\\nIntroduction\\n\\nMillets & Context\\n\\nMillets are climate-resilient grains valued for their nutritional and health benefits. Red millet is an important traditional staple in Ghana, but research on its nutritional and lutein content is limited.\\n\\nStudy Objective\\n\\nTo evaluate the proximate composition, mineral profile, and lutein extraction efficiency of red millet obtained from Cape Coast markets.\\n\\nMaterials and Methods\\n\\n1\\n\\nSample\\n\\nRed millet (P. glaucum) purchased from Abura Market, Cape Coast.\\n\\n2\\n\\nPreparation\\n\\nGrains were washed, dried, and milled into fine powder.\\n\\n3\\n\\nExtraction\\n\\n300 g of millet were subjected to cold maceration with methanol (a 4:1 solvent-to-biomass ratio) for 120 hours. The extract was filtered, evaporated using a rotary evaporator, and dried.\\n\\nProximate Composition\\n\\nProximate Composition (%)\\n\\nCarbohydrates\\n\\nProtein\\n\\nFat\\n\\nFiber\\n\\nMoisture\\n\\nThe analysis of red millet reveals its primary composition by percentage, highlighting carbohydrates as the most abundant component.\\n\\nKey Minerals\\n\\nThe analysis of red millet revealed the following concentrations of essential minerals per 100g:\\n\\nMagnesium was the most abundant mineral, followed by Calcium, Iron, and Zinc. These findings highlight the significant contribution of red millet to the dietary intake of these vital micronutrients.\\n\\nLutein Extraction and Analysis\\n\\n1\\n\\nMethanolic Extract Yield\\n\\n5.71% crude yield\\n\\n2\\n\\nTLC (Thin Layer Chromatography)\\n\\nShowed an Rf value of 0.07, which is consistent with lutein-like compounds\\n\\n3\\n\\nUV-Vis Absorbance\\n\\nAbsorbance at 343.64 nm suggested the presence of phenolics or chlorophyll derivatives rather than definitive lutein\\n\\n4\\n\\nObservation\\n\\nThe methanolic extraction gave a moderate yield of bioactive compounds. TLC suggested lutein, but UV-Vis was inconclusive, indicating the need for advanced techniques.\\n\\nConclusion\\n\\nNutritional Value\\n\\nRed millet is nutritionally valuable, providing carbohydrates, protein, fiber, and key minerals\\n\\nPublic Health Relevance\\n\\nIt is a promising source for addressing micronutrient deficiencies, especially iron deficiency anemia, due to its high iron and magnesium content\\n\\nLutein\\n\\nPreliminary evidence suggests lutein-like compounds, but further confirmation is needed\\n\\nRecommendation\\n\\nPromoting red millet can support food security, nutrition, and health in Ghana\\n\\nFuture Work & Acknowledgment\\n\\nFuture Work\\n\\n1\\n\\nApply advanced methods (HPLC-DAD\\/LC-MS) for definitive lutein identification and quantification.\\n\\n2\\n\\nInvestigate nutrient bioavailability and absorption in human diets.\\n\\n3\\n\\nDevelop value-added products and nutraceuticals from red millet.\\n\\n\\n---\\n\\nUser\'s question: what is this about?\"}]', '2025-11-19 23:24:10'),
(161, 49, 'model', '[{\"text\":\"This presentation is about the **nutritional composition and lutein extraction efficiency from red millet**, a type of grain.\\n\\nSpecifically, the study aimed to:\\n1.  **Evaluate the nutritional content** of red millet (like carbohydrates, protein, fat, fiber, moisture, and key minerals such as Magnesium, Calcium, Iron, and Zinc).\\n2.  **Assess the efficiency of extracting lutein** (a beneficial compound) from it.\\n\\nIn summary, the researchers found that red millet is nutritionally valuable, particularly for its mineral content, and holds promise for addressing micronutrient deficiencies. While they found preliminary evidence of lutein-like compounds, further advanced testing is needed for definitive confirmation.\\n\\nDoes that initial overview make sense? Is there anything in particular about \\\"red millet\\\" or \\\"nutritional composition\\\" or \\\"lutein\\\" that you\'d like to understand more deeply?\"}]', '2025-11-19 23:24:16'),
(162, 49, 'user', '[{\"text\":\"Context from uploaded file \'Nutritional-and-Phytochemical-Analysis-of-Millet-Varieties.pdf\':\\n---\\nNutritional and \\nPhytochemical Analysis of \\nMillet Varieties\\nA comprehensive study of red millet varieties from Cape Coast, Ghana, \\nexamining their mineral content, nutritional composition, and lutein \\npresence.\\n\\nBackground\\nAncient Grains\\nMillets are diverse small-\\nseeded grasses cultivated \\nglobally for their edible grains, \\nwith a long history across Asia \\nand Africa.\\nClimate Resilient\\nRemarkable resilience to \\ndrought and infertile soils, \\nthriving in 20-30\\u00b0C with only \\n200-600mm rainfall annually.\\nNutritional Powerhouse\\nContains 60-70% carbohydrates, 6-9% proteins, 10-12% fibers, \\nplus essential minerals like iron, calcium, and magnesium.\\n\\nProblem Statement & Justification\\nResearch Gap\\nDespite millet\'s prevalence in sub-Saharan Africa, \\ncomprehensive biochemical profiling of red, green, and \\nwhite varieties remains limited, especially regarding \\nbioactive phytochemicals and micronutrient densities.\\nNutritional Potential\\nProtein quality, dietary fiber, essential amino acids, and \\nmineral bioavailability remain underexplored in varietal \\ncontext, limiting valorization in health-based food \\nformulations.\\nGlobal Shift to Functional Foods\\nUrgent need to elucidate nutritional superiority of \\nmillet varieties through standardized biochemical \\nevaluation for nutraceutical applications.\\nFood Security Impact\\nCritical for breeding programs and dietary \\ndiversification strategies in low-income populations \\nwhere micronutrient deficiencies are prevalent.\\n\\nAim and Objectives\\nGeneral Objective\\nTo evaluate and compare the mineral and nutritional components among red, white and green millet varieties and evaluate \\nlutein present in them.\\n01\\nExtract Analysis\\nObtain and compute percentage yield of methanolic extracts \\nof different millet varieties\\n02\\nProximate Composition\\nQuantitatively determine proximate composition of red, white \\nand green millet varieties\\n03\\nMineral Content\\nQuantify mineral contents of red, white and green millet \\nvarieties\\n04\\nLutein Evaluation\\nEvaluate lutein presence using TLC and UV-VIS \\nspectrophotometry analysis\\n\\nMethodology\\nStudy Area\\nCape Coast Metropolis, Central Region of Ghana - major market \\nhub with diverse millet varieties from Kotokuraba and Abura \\nmarkets.\\nSample Collection\\nPurposive sampling of 500g red millet from three different \\nvendors, stored in sterile conditions and transported within 24 \\nhours.\\nLaboratory Analysis\\nAOAC standard methods for proximate composition, AAS for \\nminerals, and spectrophotometric methods for phytochemicals.\\n\\nResults & Discussion\\nProximate Composition\\nCarbohydrates Protein Moisture Crude Fiber Crude Fat Ash\\nRed millet showed excellent nutritional profile with 72.44% carbohydrates and notably high protein content of 12.06%, \\npositioning it as a valuable dietary protein source.\\n\\nMineral Analysis Results\\n125.4\\nMagnesium\\nmg\\/100g - crucial for \\nmetabolic functions\\n28.5\\nCalcium\\nmg\\/100g - essential \\nfor bone health\\n5.12\\nIron\\nmg\\/100g - superior to \\nrice and wheat\\n2.55\\nZinc\\nmg\\/100g - vital for \\nimmune function\\nThe iron content of 5.12 mg\\/100g is particularly significant for combating \\niron deficiency anemia, positioning red millet as a superior micronutrient \\nsource compared to common cereals.\\n\\nLutein Analysis Findings\\nTLC Analysis\\nRf Value: 0.07\\nLow Rf value consistent with lutein behavior, suggesting \\npresence of carotenoid compounds with limited migration \\non silica gel.\\nUV-Vis Spectroscopy\\nPeak: 343.64 nm\\nAbsorbance in UV region indicates phenolic compounds \\nrather than intact lutein (expected ~445 nm), requiring \\nadvanced HPLC analysis for confirmation.\\nCritical Finding: While TLC suggested lutein presence, UV-Vis data indicates other compounds. The 343.64 nm \\npeak is characteristic of phenolics or chlorophyll derivatives, not lutein\'s typical visible-region spectrum.\\nMethanolic Extraction Yield: 5.71% (w\\/w) indicating substantial polar metabolites but not specifically lutein content.\\n\\nConclusion\\nNutritional Excellence\\nRed millet confirmed as highly \\nnutritious grain, rich in \\ncarbohydrates (72.44%), protein \\n(12.06%), and dietary fiber \\n(4.24%).\\nMineral Powerhouse\\nValuable source of essential \\nminerals, particularly iron (5.12 \\nmg\\/100g) and magnesium (125.40 \\nmg\\/100g).\\nAnalytical Complexity\\nLutein identification requires \\nadvanced techniques - TLC \\nsuggested presence but UV-Vis \\nindicated other compounds \\npredominate.\\nThis study reinforces the importance of promoting red millet consumption as a nutrient-dense food contributing to better \\nhealth outcomes, while highlighting the need for sophisticated analytical methods for phytochemical identification.\\n\\nRecommendations & \\nLimitations\\nFuture Research Recommendations\\n1\\nAdvanced Analysis\\nConduct HPLC-DAD or LC-MS studies for definitive lutein \\nidentification and quantification\\n2\\nBioavailability Studies\\nResearch iron and lutein absorption and utilization by \\nhuman body\\n3\\nProduct Development\\nDevelop novel food products and nutraceuticals leveraging \\nhigh nutritional value\\nStudy Limitations\\nSamples from restricted geographical region may not capture full \\ngenetic variability\\nNo in vivo validation of bioactive compound effects\\nProcessing techniques\' impact on nutritional composition not \\nevaluated\\nLimited biological replicates due to resource constraints\\n---\\n\\nUser\'s question: What is this about?\"}]', '2025-11-19 23:24:39'),
(163, 49, 'model', '[{\"text\":\"This document is a comprehensive study titled \\\"**Nutritional and Phytochemical Analysis of Millet Varieties**,\\\" with a particular focus on red millet from Cape Coast, Ghana.\\n\\nIts main purpose was to:\\n\\n1.  **Evaluate and compare the mineral and nutritional components** (like carbohydrates, protein, fiber, and essential minerals) across red, white, and green millet varieties.\\n2.  **Assess the presence of lutein**, a beneficial phytochemical, in these millets.\\n\\nIn essence, the study found that **red millet is a highly nutritious grain**, rich in carbohydrates, protein, and dietary fiber. It\'s also a valuable source of essential minerals, especially **iron** (which is significant for combating iron deficiency anemia) and **magnesium**.\\n\\nRegarding lutein, while preliminary tests (TLC) suggested its presence, more advanced analytical techniques are needed for definitive identification and quantification because other tests (UV-Vis) indicated the presence of other compounds like phenolics instead of clear lutein.\\n\\nOverall, the study reinforces the importance of promoting red millet consumption for better health and highlights the need for further sophisticated analysis of its beneficial compounds.\\n\\nDoes this summary help you understand the core of the document? Would you like to delve deeper into any specific aspect, like what \\\"lutein\\\" is or why \\\"iron deficiency anemia\\\" is mentioned?\"}]', '2025-11-19 23:24:45');
INSERT INTO `messages` (`id`, `conversation_id`, `role`, `content`, `created_at`) VALUES
(166, 52, 'user', '[{\"inline_data\":{\"mime_type\":\"image\\/jpeg\",\"data\":\"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\"}},{\"text\":\"what is this\\/\"}]', '2025-11-19 23:45:21');
INSERT INTO `messages` (`id`, `conversation_id`, `role`, `content`, `created_at`) VALUES
(167, 52, 'model', '[{\"text\":\"That\'s a great question! Based on the image, this plant appears to be **Sorghum**.\\n\\nSorghum is a versatile and important cereal grain, belonging to the grass family (Poaceae), much like corn, wheat, or rice.\\n\\nHere\'s a bit more to help you understand it:\\n\\n*   **Appearance**: You can see its characteristic large, dense cluster of seeds at the top of the stalk, called a panicle or head. The individual grains are small, round, and can vary in color (reddish-brown, yellow, white). The leaves are broad, similar to corn.\\n*   **Adaptations**: One of its most notable features is its exceptional **drought resistance**. This makes it a crucial crop in arid and semi-arid regions around the world where other grains might struggle to grow.\\n*   **Uses**:\\n    *   **Food**: It\'s a staple food for millions of people, particularly in parts of Africa and Asia, where it\'s ground into flour for bread, porridge, or used to make beverages. It\'s also gluten-free!\\n    *   **Feed**: Globally, a significant portion of sorghum is used as animal feed.\\n    *   **Biofuel**: It can also be used in the production of ethanol and other biofuels.\\n\\nDoes learning about its drought resistance or its various uses help you understand why it\'s such an important crop globally?\"}]', '2025-11-19 23:45:29');

-- --------------------------------------------------------

--
-- Table structure for table `users`
--

CREATE TABLE `users` (
  `id` int(11) NOT NULL,
  `username` varchar(50) NOT NULL,
  `full_name` varchar(255) DEFAULT NULL,
  `email` varchar(100) NOT NULL,
  `password_hash` varchar(255) NOT NULL,
  `created_at` timestamp NOT NULL DEFAULT current_timestamp(),
  `updated_at` timestamp NOT NULL DEFAULT current_timestamp() ON UPDATE current_timestamp()
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `users`
--

INSERT INTO `users` (`id`, `username`, `full_name`, `email`, `password_hash`, `created_at`, `updated_at`) VALUES
(1, 'primus', NULL, 'anthonybonney13@gmail.com', '$argon2id$v=19$m=65536,t=4,p=1$ZXVJbkZBN05JNTZsMEtOeQ$R0PoeDzAPVNnku5mgPQZRYAIzokPYLMyNU/0wfcwS2s', '2025-10-28 01:33:10', '2025-10-28 01:33:10'),
(2, 'DelppY', NULL, 'delppy1@gmail.com', '$argon2id$v=19$m=65536,t=4,p=1$emlkdXRscVEvLlpXbzNhOA$uZlegXjZ07f6ljq5uhFHo8oX8DeFRA2+Rnm8Xi2uSM0', '2025-10-28 07:42:10', '2025-10-28 07:42:10'),
(3, 'johnogunnusi2987', NULL, 'johnogunnusi2019@gmail.com', '$argon2id$v=19$m=65536,t=4,p=1$RWVZcXdFSWlDUzBVUmlGRw$h3djdH/FRgBs0wYZVqFitl56Fsgis8zXdpUk1u3iPWw', '2025-10-30 12:15:59', '2025-10-30 12:15:59'),
(4, 'Pearl', NULL, 'pearlkorang1@gmail.com', '$argon2id$v=19$m=65536,t=4,p=1$dmN4UXd1dno4ZmVjZUd6VQ$tNIGdex3MbwrlNPxxQ1vdkxQawWendAiE477VDmhS+w', '2025-11-03 22:06:10', '2025-11-03 22:06:10'),
(5, 'Princess Cheryssé ', NULL, 'naaayilor@gmail.com', '$argon2id$v=19$m=65536,t=4,p=1$ODBPNnAwR2ZKQ3B0aWJPag$EAXyMnCKgiOth+Z+w9GWoN8i4J/evdNal2Xsv4mQSkY', '2025-11-10 07:17:15', '2025-11-10 07:17:15'),
(6, 'whispernessa', 'Vanessa Parker', 'whispernessa56@gmail.com', '$argon2id$v=19$m=65536,t=4,p=1$bzNVVTQ4MmFsU2dOQ2t3Ug$d6qhevnZBVWFB6f+Q6riSOGDdZSKmko0GhsgYwL/l3A', '2025-11-18 00:50:51', '2025-11-18 00:50:51');

--
-- Indexes for dumped tables
--

--
-- Indexes for table `conversations`
--
ALTER TABLE `conversations`
  ADD PRIMARY KEY (`id`),
  ADD KEY `user_id` (`user_id`);

--
-- Indexes for table `messages`
--
ALTER TABLE `messages`
  ADD PRIMARY KEY (`id`),
  ADD KEY `conversation_id` (`conversation_id`);

--
-- Indexes for table `users`
--
ALTER TABLE `users`
  ADD PRIMARY KEY (`id`),
  ADD UNIQUE KEY `username` (`username`),
  ADD UNIQUE KEY `email` (`email`);

--
-- AUTO_INCREMENT for dumped tables
--

--
-- AUTO_INCREMENT for table `conversations`
--
ALTER TABLE `conversations`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=53;

--
-- AUTO_INCREMENT for table `messages`
--
ALTER TABLE `messages`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=168;

--
-- AUTO_INCREMENT for table `users`
--
ALTER TABLE `users`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=7;

--
-- Constraints for dumped tables
--

--
-- Constraints for table `conversations`
--
ALTER TABLE `conversations`
  ADD CONSTRAINT `conversations_ibfk_1` FOREIGN KEY (`user_id`) REFERENCES `users` (`id`) ON DELETE CASCADE;

--
-- Constraints for table `messages`
--
ALTER TABLE `messages`
  ADD CONSTRAINT `messages_ibfk_1` FOREIGN KEY (`conversation_id`) REFERENCES `conversations` (`id`) ON DELETE CASCADE;
COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
